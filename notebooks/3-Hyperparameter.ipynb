{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eM6m2JHf5q5"
   },
   "source": [
    "# Experiment with different classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to try\n",
    "\n",
    "1. Advanced Ensemble Techniques\n",
    "    - **Blending**: We’ll implement a blending technique where a meta-model is trained on a holdout set (a part of the training data not seen by the base models).\n",
    "    - **Bagging**: We’ll explore bagging, which involves training multiple instances of the same model on different subsets of the training data.\n",
    "\n",
    "2. Class Balancing Techniques\n",
    "    - **ADASYN**: We’ll experiment with the ADASYN technique for generating synthetic samples to balance the classes.\n",
    "    - **Class Weighting**: In some algorithms like Logistic Regression or SVM, we can assign weights to classes inversely proportional to their frequency.\n",
    "\n",
    "3. Regularization\n",
    "We’ll apply L1 or L2 regularization to models like Logistic Regression, SVM, or any other linear models used in your ensemble.\n",
    "\n",
    "4.  Hyperparameter Tuning\n",
    "We'll use grid search to find the best hyperparameters for the models.\n",
    "\n",
    "5. Cross-Validation\n",
    "We'll use cross-validation to validate the models' performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Load the train data\n",
    "train_path = r\"../data/clean/test.parquet\"\n",
    "data_train = pd.read_parquet(train_path)\n",
    "\n",
    "# test data\n",
    "test_path = r\"../data/clean/test.parquet\"\n",
    "data_test = pd.read_parquet(test_path)\n",
    "\n",
    "# stack the data\n",
    "data = pd.concat([data_train, data_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "y = data.pop('Y')\n",
    "X = data\n",
    "# Handle imbalanced data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep on improving our data pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "Accuracy: 0.8333333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83         6\n",
      "           1       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.83      0.83      0.83        12\n",
      "weighted avg       0.83      0.83      0.83        12\n",
      "\n",
      "============================================================\n",
      "Model: RandomForest\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "============================================================\n",
      "Model: SVM\n",
      "Accuracy: 0.8333333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83         6\n",
      "           1       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.83      0.83      0.83        12\n",
      "weighted avg       0.83      0.83      0.83        12\n",
      "\n",
      "============================================================\n",
      "Model: GradientBoosting\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "============================================================\n",
      "Model: XGBoost\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the models with pipelines\n",
    "pipelines = {\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ]),\n",
    "    'RandomForest': Pipeline([\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "    'SVM': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', SVC(random_state=42))\n",
    "    ]),\n",
    "    'GradientBoosting': Pipeline([\n",
    "        ('clf', GradientBoostingClassifier(random_state=42))\n",
    "    ]),\n",
    "    'XGBoost': Pipeline([\n",
    "        ('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    results[name] = (accuracy, report)\n",
    "\n",
    "# Print results\n",
    "for model_name, (accuracy, report) in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCH2VY_RrTJk",
    "outputId": "684e569e-4495-41d2-d628-27b92bcc3a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters for LogisticRegression...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Tuning hyperparameters for RandomForest...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 6 is smaller than n_iter=20. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters for SVM...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Tuning hyperparameters for GradientBoosting...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 6 is smaller than n_iter=20. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters for XGBoost...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best LogisticRegression Model\n",
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73         6\n",
      "           1       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.76      0.75      0.75        12\n",
      "weighted avg       0.76      0.75      0.75        12\n",
      "\n",
      "Best Parameters: {'memory': None, 'steps': [('scaler', StandardScaler()), ('clf', LogisticRegression(C=0.1, max_iter=1000, random_state=42))], 'verbose': False, 'scaler': StandardScaler(), 'clf': LogisticRegression(C=0.1, max_iter=1000, random_state=42), 'scaler__copy': True, 'scaler__with_mean': True, 'scaler__with_std': True, 'clf__C': 0.1, 'clf__class_weight': None, 'clf__dual': False, 'clf__fit_intercept': True, 'clf__intercept_scaling': 1, 'clf__l1_ratio': None, 'clf__max_iter': 1000, 'clf__multi_class': 'deprecated', 'clf__n_jobs': None, 'clf__penalty': 'l2', 'clf__random_state': 42, 'clf__solver': 'lbfgs', 'clf__tol': 0.0001, 'clf__verbose': 0, 'clf__warm_start': False}\n",
      "============================================================\n",
      "Best RandomForest Model\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Best Parameters: {'memory': None, 'steps': [('clf', RandomForestClassifier(min_samples_split=5, random_state=42))], 'verbose': False, 'clf': RandomForestClassifier(min_samples_split=5, random_state=42), 'clf__bootstrap': True, 'clf__ccp_alpha': 0.0, 'clf__class_weight': None, 'clf__criterion': 'gini', 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__max_leaf_nodes': None, 'clf__max_samples': None, 'clf__min_impurity_decrease': 0.0, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 5, 'clf__min_weight_fraction_leaf': 0.0, 'clf__monotonic_cst': None, 'clf__n_estimators': 100, 'clf__n_jobs': None, 'clf__oob_score': False, 'clf__random_state': 42, 'clf__verbose': 0, 'clf__warm_start': False}\n",
      "============================================================\n",
      "Best SVM Model\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Best Parameters: {'memory': None, 'steps': [('scaler', StandardScaler()), ('clf', SVC(C=10, random_state=42))], 'verbose': False, 'scaler': StandardScaler(), 'clf': SVC(C=10, random_state=42), 'scaler__copy': True, 'scaler__with_mean': True, 'scaler__with_std': True, 'clf__C': 10, 'clf__break_ties': False, 'clf__cache_size': 200, 'clf__class_weight': None, 'clf__coef0': 0.0, 'clf__decision_function_shape': 'ovr', 'clf__degree': 3, 'clf__gamma': 'scale', 'clf__kernel': 'rbf', 'clf__max_iter': -1, 'clf__probability': False, 'clf__random_state': 42, 'clf__shrinking': True, 'clf__tol': 0.001, 'clf__verbose': False}\n",
      "============================================================\n",
      "Best GradientBoosting Model\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Best Parameters: {'memory': None, 'steps': [('clf', GradientBoostingClassifier(max_depth=5, random_state=42))], 'verbose': False, 'clf': GradientBoostingClassifier(max_depth=5, random_state=42), 'clf__ccp_alpha': 0.0, 'clf__criterion': 'friedman_mse', 'clf__init': None, 'clf__learning_rate': 0.1, 'clf__loss': 'log_loss', 'clf__max_depth': 5, 'clf__max_features': None, 'clf__max_leaf_nodes': None, 'clf__min_impurity_decrease': 0.0, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__min_weight_fraction_leaf': 0.0, 'clf__n_estimators': 100, 'clf__n_iter_no_change': None, 'clf__random_state': 42, 'clf__subsample': 1.0, 'clf__tol': 0.0001, 'clf__validation_fraction': 0.1, 'clf__verbose': 0, 'clf__warm_start': False}\n",
      "============================================================\n",
      "Best XGBoost Model\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Best Parameters: {'memory': None, 'steps': [('clf', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='logloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=42, ...))], 'verbose': False, 'clf': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='logloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=42, ...), 'clf__objective': 'binary:logistic', 'clf__base_score': None, 'clf__booster': None, 'clf__callbacks': None, 'clf__colsample_bylevel': None, 'clf__colsample_bynode': None, 'clf__colsample_bytree': None, 'clf__device': None, 'clf__early_stopping_rounds': None, 'clf__enable_categorical': False, 'clf__eval_metric': 'logloss', 'clf__feature_types': None, 'clf__gamma': None, 'clf__grow_policy': None, 'clf__importance_type': None, 'clf__interaction_constraints': None, 'clf__learning_rate': 0.1, 'clf__max_bin': None, 'clf__max_cat_threshold': None, 'clf__max_cat_to_onehot': None, 'clf__max_delta_step': None, 'clf__max_depth': 5, 'clf__max_leaves': None, 'clf__min_child_weight': None, 'clf__missing': nan, 'clf__monotone_constraints': None, 'clf__multi_strategy': None, 'clf__n_estimators': 100, 'clf__n_jobs': None, 'clf__num_parallel_tree': None, 'clf__random_state': 42, 'clf__reg_alpha': None, 'clf__reg_lambda': None, 'clf__sampling_method': None, 'clf__scale_pos_weight': None, 'clf__subsample': None, 'clf__tree_method': None, 'clf__validate_parameters': None, 'clf__verbosity': None, 'clf__use_label_encoder': False}\n",
      "============================================================\n",
      "Cross-Validation Accuracy for LogisticRegression: 0.7833333333333334 ± 0.04082482904638632\n",
      "Cross-Validation Accuracy for RandomForest: 1.0 ± 0.0\n",
      "Cross-Validation Accuracy for SVM: 0.9666666666666666 ± 0.04082482904638632\n",
      "Cross-Validation Accuracy for GradientBoosting: 0.9833333333333334 ± 0.03333333333333335\n",
      "Cross-Validation Accuracy for XGBoost: 1.0 ± 0.0\n",
      "Voting Classifier Model\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Cross-Validation Accuracy for Voting Classifier: 1.0 ± 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_voting_classifier_{date_time}.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning using RandomizedSearchCV\n",
    "tuning_params = {\n",
    "    'RandomForest': {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__max_depth': [None, 10, 20, 30],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'clf__max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'clf__max_depth': [3, 5, 7]\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    print(f\"Tuning hyperparameters for {name}...\")\n",
    "    random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=tuning_params[name], n_iter=20, cv=5, n_jobs=-1, verbose=2, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_models[name] = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the best models\n",
    "for name, best_model in best_models.items():\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(f\"Best {name} Model\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"Best Parameters:\", best_model.get_params())\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Cross-Validation for the best models\n",
    "for name, best_model in best_models.items():\n",
    "    cv_scores = cross_val_score(best_model, X_res, y_res, cv=StratifiedKFold(5), verbose=0)\n",
    "    print(f\"Cross-Validation Accuracy for {name}: {cv_scores.mean()} ± {cv_scores.std()}\")\n",
    "\n",
    "# Ensemble Model - Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', best_models['LogisticRegression']),\n",
    "    ('rf', best_models['RandomForest']),\n",
    "    ('svm', best_models['SVM']),\n",
    "    ('gb', best_models['GradientBoosting']),\n",
    "    ('xgb', best_models['XGBoost'])\n",
    "], voting='hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Voting Classifier Model\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Cross-Validation for Voting Classifier\n",
    "cv_scores = cross_val_score(voting_clf, X_res, y_res, cv=StratifiedKFold(5))\n",
    "print(f\"Cross-Validation Accuracy for Voting Classifier: {cv_scores.mean()} ± {cv_scores.std()}\")\n",
    "\n",
    "# Save the best models and voting classifier\n",
    "date_time = pd.Timestamp.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "for name, best_model in best_models.items():\n",
    "    joblib.dump(best_model, f'../models/{date_time}/best_{name}_model.pkl')\n",
    "joblib.dump(voting_clf, f'../models/{date_time}/best_voting_classifier_.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sz3-rRa4sebE",
    "outputId": "5a1b41dd-5695-450c-8482-934c9bcd0c97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 08:55:46,453] A new study created in memory with name: no-name-b64d72ad-03dd-418f-8a98-4450b23783a7\n",
      "[I 2024-08-20 08:55:47,299] Trial 0 finished with value: 0.7977777777777777 and parameters: {'n_estimators': 117, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.7977777777777777.\n",
      "[I 2024-08-20 08:55:48,071] Trial 1 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 101, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:49,131] Trial 2 finished with value: 0.7955555555555555 and parameters: {'n_estimators': 153, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:49,581] Trial 3 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 63, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:50,876] Trial 4 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 200, 'max_depth': 25, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:51,933] Trial 5 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 157, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:52,859] Trial 6 finished with value: 0.7977777777777777 and parameters: {'n_estimators': 141, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:53,898] Trial 7 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 140, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:54,629] Trial 8 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 99, 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:56,039] Trial 9 finished with value: 0.7955555555555555 and parameters: {'n_estimators': 192, 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:56,538] Trial 10 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 62, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:56,970] Trial 11 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 53, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:57,668] Trial 12 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 89, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:58,296] Trial 13 finished with value: 0.8577777777777778 and parameters: {'n_estimators': 77, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:59,043] Trial 14 finished with value: 0.7977777777777777 and parameters: {'n_estimators': 108, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:55:59,594] Trial 15 finished with value: 0.86 and parameters: {'n_estimators': 81, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:00,050] Trial 16 finished with value: 0.8577777777777778 and parameters: {'n_estimators': 67, 'max_depth': 27, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:00,465] Trial 17 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 51, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:01,087] Trial 18 finished with value: 0.7977777777777777 and parameters: {'n_estimators': 92, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:01,849] Trial 19 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 108, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:02,780] Trial 20 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 128, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:03,144] Trial 21 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 50, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:03,709] Trial 22 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 77, 'max_depth': 29, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:04,193] Trial 23 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 65, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:04,673] Trial 24 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 60, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:05,228] Trial 25 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 76, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:05,917] Trial 26 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 97, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:07,113] Trial 27 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 171, 'max_depth': 23, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:07,482] Trial 28 finished with value: 0.86 and parameters: {'n_estimators': 50, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:08,330] Trial 29 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 122, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:09,081] Trial 30 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 107, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:09,697] Trial 31 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 89, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:10,291] Trial 32 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 87, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:10,764] Trial 33 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 68, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:11,212] Trial 34 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 59, 'max_depth': 23, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:11,709] Trial 35 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 72, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:12,404] Trial 36 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 99, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:13,031] Trial 37 finished with value: 0.7977777777777777 and parameters: {'n_estimators': 85, 'max_depth': 27, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:13,808] Trial 38 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 114, 'max_depth': 29, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:14,255] Trial 39 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 62, 'max_depth': 22, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:15,168] Trial 40 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 139, 'max_depth': 23, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:15,912] Trial 41 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 110, 'max_depth': 29, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:16,746] Trial 42 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 129, 'max_depth': 28, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:17,573] Trial 43 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 120, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:18,197] Trial 44 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 93, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:18,900] Trial 45 finished with value: 0.7977777777777777 and parameters: {'n_estimators': 107, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:19,304] Trial 46 finished with value: 0.7977777777777778 and parameters: {'n_estimators': 57, 'max_depth': 25, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:19,990] Trial 47 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 102, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:20,558] Trial 48 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 82, 'max_depth': 25, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:56:21,066] Trial 49 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 73, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.8800000000000001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Model with Optuna\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Voting Classifier Model\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Cross-Validation Accuracy for Voting Classifier: 1.0 ± 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['best_voting_classifier_2024-08-20_08-56-23.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tuning using Optuna for an example model (Random Forest)\n",
    "def objective(trial):\n",
    "    param_grid = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 30),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n",
    "    }\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', RandomForestClassifier(random_state=42, **param_grid))\n",
    "    ])\n",
    "\n",
    "    return cross_val_score(\n",
    "        pipeline, X_train, y_train, cv=StratifiedKFold(5), verbose=0\n",
    "        ).mean()\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "best_params = study.best_params\n",
    "\n",
    "# Train and evaluate the best RandomForest model with optimized hyperparameters\n",
    "best_rf_pipeline = Pipeline([\n",
    "    ('clf', RandomForestClassifier(random_state=42, **best_params))\n",
    "])\n",
    "best_rf_pipeline.fit(X_train, y_train)\n",
    "y_pred = best_rf_pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Best RandomForest Model with Optuna\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Evaluate the ensemble model (Voting Classifier)\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', pipelines['LogisticRegression']),\n",
    "    ('rf', pipelines['RandomForest']),\n",
    "    ('svm', pipelines['SVM']),\n",
    "    ('gb', pipelines['GradientBoosting']),\n",
    "    ('xgb', pipelines['XGBoost'])\n",
    "], voting='hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Voting Classifier Model\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Cross-Validation for Voting Classifier\n",
    "cv_scores = cross_val_score(voting_clf, X_res, y_res, cv=StratifiedKFold(5))\n",
    "print(f\"Cross-Validation Accuracy for Voting Classifier: {cv_scores.mean()} ± {cv_scores.std()}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Save the best models and voting classifier\n",
    "date_time = pd.Timestamp.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "for name, best_model in best_models.items():\n",
    "    joblib.dump(best_model, f'../models/{date_time}/best_{name}_model.pkl')\n",
    "joblib.dump(voting_clf, f'../models/{date_time}/best_voting_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0cfEMTpxFln"
   },
   "source": [
    "## Implementation of Stacking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackingClassifier\n",
    "+ polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "A0LzoF9syZkF",
    "outputId": "dd1fcf6d-0343-4159-c6a3-aac4e1e30ba2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Model\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy for Stacking Classifier: 1.0 ± 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAHFCAYAAAB4oGqqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtvUlEQVR4nO3deXQUdb7//1cnJJ2wJJJggDCAgKJsQlgnOMjOJSCQGUBwZUcBFQSRCVwJimMAvaKyhH0RlcCAcFGRK4osGqJhcwHGhUVkJhECshihiaF+f/gjX5tUoBu60qnm+ZhT55hPV33q3TnD4c37/flUOQzDMAQAAHCZIH8HAAAASiaSBAAAYIokAQAAmCJJAAAApkgSAACAKZIEAABgiiQBAACYIkkAAACmSBIAAIApkgQEtC+//FIDBgxQjRo1FBYWprJly6px48aaNm2aTp48aem9d+/erdatWysyMlIOh0OvvPKKz+/hcDg0adIkn897NUuWLJHD4ZDD4dDmzZsLfW4Yhm699VY5HA61adPmmu4xe/ZsLVmyxKtrNm/eXGRMALxXyt8BAFaZP3++hg8frttvv11jx45V3bp1lZeXpx07dmjOnDnavn271qxZY9n9Bw4cqNzcXKWlpal8+fK65ZZbfH6P7du3609/+pPP5/VUuXLltHDhwkKJwJYtW3TgwAGVK1fumueePXu2KlSooP79+3t8TePGjbV9+3bVrVv3mu8L4P8hSUBA2r59u4YNG6aOHTtq7dq1cjqdBZ917NhRY8aM0YYNGyyN4euvv9aQIUOUkJBg2T3+/Oc/Wza3J/r06aM333xTs2bNUkRERMH4woULFR8frzNnzhRLHHl5eXI4HIqIiPD77wQIJLQbEJBeeOEFORwOzZs3zy1BuCQ0NFTdu3cv+PnixYuaNm2a7rjjDjmdTsXExOjhhx/W0aNH3a5r06aN6tevr8zMTLVq1UqlS5dWzZo1NWXKFF28eFHS/yvF//bbb0pNTS0oy0vSpEmTCv77jy5dc/jw4YKxTZs2qU2bNoqOjlZ4eLiqVaumnj176tdffy04x6zd8PXXX6tHjx4qX768wsLC1KhRIy1dutTtnEtl+eXLl2vChAmKjY1VRESEOnTooG+++cazX7Kk++67T5K0fPnygrHTp09r9erVGjhwoOk1zz77rFq0aKGoqChFRESocePGWrhwof74rrlbbrlFe/fu1ZYtWwp+f5cqMZdiX7ZsmcaMGaMqVarI6XTq+++/L9RuyMnJUdWqVdWyZUvl5eUVzL9v3z6VKVNGDz30kMffFbgRkSQg4OTn52vTpk1q0qSJqlat6tE1w4YN07hx49SxY0etW7dOkydP1oYNG9SyZUvl5OS4nZudna0HHnhADz74oNatW6eEhAQlJSXpjTfekCR17dpV27dvlyT16tVL27dvL/jZU4cPH1bXrl0VGhqqRYsWacOGDZoyZYrKlCmjCxcuFHndN998o5YtW2rv3r167bXX9Pbbb6tu3brq37+/pk2bVuj88ePH64cfftCCBQs0b948fffdd+rWrZvy8/M9ijMiIkK9evXSokWLCsaWL1+uoKAg9enTp8jv9sgjj2jlypV6++239be//U2PP/64Jk+eXHDOmjVrVLNmTcXFxRX8/i5vDSUlJenIkSOaM2eO3nnnHcXExBS6V4UKFZSWlqbMzEyNGzdOkvTrr7+qd+/eqlatmubMmePR9wRuWAYQYLKzsw1JRt++fT06f//+/YYkY/jw4W7jn332mSHJGD9+fMFY69atDUnGZ5995nZu3bp1jf/6r/9yG5NkjBgxwm0sOTnZMPtjt3jxYkOScejQIcMwDGPVqlWGJGPPnj1XjF2SkZycXPBz3759DafTaRw5csTtvISEBKN06dLGqVOnDMMwjI8//tiQZHTp0sXtvJUrVxqSjO3bt1/xvpfizczMLJjr66+/NgzDMJo1a2b079/fMAzDqFevntG6desi58nPzzfy8vKM5557zoiOjjYuXrxY8FlR11663913313kZx9//LHb+NSpUw1Jxpo1a4x+/foZ4eHhxpdffnnF7wjAMKgk4Ib38ccfS1KhBXLNmzdXnTp19NFHH7mNV6pUSc2bN3cbu/POO/XDDz/4LKZGjRopNDRUQ4cO1dKlS3Xw4EGPrtu0aZPat29fqILSv39//frrr4UqGn9suUi/fw9JXn2X1q1bq1atWlq0aJG++uorZWZmFtlquBRjhw4dFBkZqeDgYIWEhGjixIk6ceKEjh075vF9e/bs6fG5Y8eOVdeuXXXfffdp6dKlmjFjhho0aODx9cCNiiQBAadChQoqXbq0Dh065NH5J06ckCRVrly50GexsbEFn18SHR1d6Dyn06lz585dQ7TmatWqpQ8//FAxMTEaMWKEatWqpVq1aunVV1+94nUnTpwo8ntc+vyPLv8ul9ZvePNdHA6HBgwYoDfeeENz5sxR7dq11apVK9NzP//8c3Xq1EnS77tPPv30U2VmZmrChAle39fse14pxv79++v8+fOqVKkSaxEAD5EkIOAEBwerffv22rlzZ6GFh2Yu/UWZlZVV6LP//Oc/qlChgs9iCwsLkyS5XC638cvXPUhSq1at9M477+j06dPKyMhQfHy8Ro0apbS0tCLnj46OLvJ7SPLpd/mj/v37KycnR3PmzNGAAQOKPC8tLU0hISF69913de+996ply5Zq2rTpNd3TbAFoUbKysjRixAg1atRIJ06c0FNPPXVN9wRuNCQJCEhJSUkyDENDhgwxXeiXl5end955R5LUrl07SSpYeHhJZmam9u/fr/bt2/ssrksr9L/88ku38UuxmAkODlaLFi00a9YsSdKuXbuKPLd9+/batGlTQVJwyeuvv67SpUtbtj2wSpUqGjt2rLp166Z+/foVeZ7D4VCpUqUUHBxcMHbu3DktW7as0Lm+qs7k5+frvvvuk8Ph0Pvvv6+UlBTNmDFDb7/99nXPDQQ6npOAgBQfH6/U1FQNHz5cTZo00bBhw1SvXj3l5eVp9+7dmjdvnurXr69u3brp9ttv19ChQzVjxgwFBQUpISFBhw8f1jPPPKOqVavqySef9FlcXbp0UVRUlAYNGqTnnntOpUqV0pIlS/Tjjz+6nTdnzhxt2rRJXbt2VbVq1XT+/PmCHQQdOnQocv7k5GS9++67atu2rSZOnKioqCi9+eabeu+99zRt2jRFRkb67LtcbsqUKVc9p2vXrnr55Zd1//33a+jQoTpx4oReeukl022qDRo0UFpamlasWKGaNWsqLCzsmtYRJCcna9u2bfrggw9UqVIljRkzRlu2bNGgQYMUFxenGjVqeD0ncKMgSUDAGjJkiJo3b67p06dr6tSpys7OVkhIiGrXrq37779fjz32WMG5qampqlWrlhYuXKhZs2YpMjJSnTt3VkpKiukahGsVERGhDRs2aNSoUXrwwQd10003afDgwUpISNDgwYMLzmvUqJE++OADJScnKzs7W2XLllX9+vW1bt26gp6+mdtvv13p6ekaP368RowYoXPnzqlOnTpavHixV08utEq7du20aNEiTZ06Vd26dVOVKlU0ZMgQxcTEaNCgQW7nPvvss8rKytKQIUN09uxZVa9e3e05Ep7YuHGjUlJS9Mwzz7hVhJYsWaK4uDj16dNHn3zyiUJDQ33x9YCA4zCMPzzBBAAA4P/HmgQAAGCKJAEAAJgiSQAAAKZIEgAACFD//ve/9eCDDyo6OlqlS5dWo0aNtHPnTo+vZ3cDAAAB6Oeff9Zdd92ltm3b6v3331dMTIwOHDigm266yeM52N0AAEAA+vvf/65PP/1U27Ztu+Y5aDcAAGATLpdLZ86ccTsuf8z7JevWrVPTpk3Vu3dvxcTEKC4uTvPnz/fqfgFZSQiPe+zqJwE3oJ8zZ/o7BKDECSuGxruv/l4a16OCnn32Wbex5ORkTZo0qdC5l94VM3r0aPXu3Vuff/65Ro0apblz5+rhhx/26H4kCcANhCQBKMxOScKpjP8pVDlwOp2mjzYPDQ1V06ZNlZ6eXjD2xBNPKDMzs9Br44vCwkUAAKzm8E13v6iEwEzlypVVt25dt7E6depo9erVHt+PJAEAAKt58WpzX7nrrrv0zTffuI19++23ql69usdzkCQAAGA1H1USvPHkk0+qZcuWeuGFF3Tvvffq888/17x58zRv3jyP52B3AwAAAahZs2Zas2aNli9frvr162vy5Ml65ZVX9MADD3g8B5UEAACs5od2gyTdc889uueee675epIEAACs5od2gy/YM2oAAGA5KgkAAFjNT+2G60WSAACA1Wg3AACAQEIlAQAAq9FuAAAApmg3AACAQEIlAQAAq9FuAAAApmzabiBJAADAajatJNgztQEAAJajkgAAgNVoNwAAAFM2TRLsGTUAALAclQQAAKwWZM+FiyQJAABYjXYDAAAIJFQSAACwmk2fk0CSAACA1Wg3AACAQEIlAQAAq9FuAAAApmzabiBJAADAajatJNgztQEAAJajkgAAgNVoNwAAAFO0GwAAQCChkgAAgNVoNwAAAFO0GwAAQCChkgAAgNVoNwAAAFM2TRLsGTUAALAclQQAAKxm04WLJAkAAFjNpu0GkgQAAKxm00qCPVMbAABgOSoJAABYjXYDAAAwRbsBAAAEEioJAABYzGHTSgJJAgAAFrNrkkC7AQAAmKKSAACA1exZSCBJAADAarQbAABAQKGSAACAxexaSSBJAADAYiQJAADAlF2TBNYkAAAQgCZNmiSHw+F2VKpUyas5qCQAAGA1PxUS6tWrpw8//LDg5+DgYK+uJ0kAAMBi/mo3lCpVyuvqwR/RbgAAIEB99913io2NVY0aNdS3b18dPHjQq+upJAAAYDFfVRJcLpdcLpfbmNPplNPpLHRuixYt9Prrr6t27dr66aef9Pzzz6tly5bau3evoqOjPboflQQAACx2+QLCaz1SUlIUGRnpdqSkpJjeMyEhQT179lSDBg3UoUMHvffee5KkpUuXehw3lQQAAGwiKSlJo0ePdhszqyKYKVOmjBo0aKDvvvvO4/uRJAAAYDFftRuKai14wuVyaf/+/WrVqpXH19BuAADAag4fHV546qmntGXLFh06dEifffaZevXqpTNnzqhfv34ez0ElAQCAAHT06FHdd999ysnJ0c0336w///nPysjIUPXq1T2egyQBAACL+eM5CWlpadc9B0kCAAAWs+u7G0gSAACwmF2TBBYuAgAAU1QSAACwmj0LCSQJAABYjXYDAAAIKFQSAACwmF0rCSQJAABYzK5JAu0GAABgikoCAAAWs2slgSQBAACr2TNHoN0AAADMUUkAAMBitBsAAIApkgQAAGDKrkkCaxIAAIApKgkAAFjNnoUEkgQAAKxGuwEAAAQUkgRYIvbmSC16/mEd/XiqTqS/rIy0vyuuTlV/hwX43YrlbyqhUzs1i2ugvr3/pl07d/g7JBQDh8Phk6O40W6Az91ULlyblozWlszvlPjYbB07eVY1q1bQqbPn/B0a4Fcb3l+vaVNSNOGZZDWKa6xVK9M0/JEhWrPuPVWOjfV3eLCQXdsNJAnwuTEDOupo9s96ZNIbBWNHsk76MSKgZFi2dLH+2rOn/tartyTp6aQJSk//RCtXLNfIJ8f4OTqgML8mCUePHlVqaqrS09OVnZ0th8OhihUrqmXLlnr00UdVtSrlaTvq2rqBPkzfrzenDdRfmtym/xw7pXkrt2nxmnR/hwb4Td6FC9q/b68GDh7qNh7f8i59sWe3n6JCcbFrJcFvaxI++eQT1alTR2vWrFHDhg318MMP68EHH1TDhg21du1a1atXT59++qm/wsN1qFGlgob0bqXvjxxX9+GztGDVJ/qfp3vp/nua+zs0wG9+PvWz8vPzFR0d7TYeHV1BOTnH/RQVio3DR0cx81sl4cknn9TgwYM1ffr0Ij8fNWqUMjMzrziPy+WSy+VyGzMu5ssRFOyzWOGdoCCHdu07ouSZ70iSvvjmqOrWqqyhvVvprXc/93N0gH9d/i9KwzBs+69MBD6/VRK+/vprPfroo0V+/sgjj+jrr7++6jwpKSmKjIx0O377aacvQ4WXsnPOaP/BbLexfx3KVtVK5f0UEeB/5W8qr+DgYOXk5LiNnzx5QtHRFfwUFYqLXXc3+C1JqFy5stLTi+5Rb9++XZUrV77qPElJSTp9+rTbUapiE1+GCi9t33NQtavHuI3dVi2GxYu4oYWEhqpO3XrKSHdvo2akp6thozg/RYXiYtckwW/thqeeekqPPvqodu7cqY4dO6pixYpyOBzKzs7Wxo0btWDBAr3yyitXncfpdMrpdLqN0WrwrxlvbNLHS8Zo7MBOWr1xl5rVu0UDe96lxyYv93dogF891G+AJvz9adWtX18NG8Zp9T9XKCsrS7379PV3aLCYXTtKfksShg8frujoaE2fPl1z585Vfn6+JCk4OFhNmjTR66+/rnvvvddf4eE67Nx3RH3GzNdzj3fX+KEJOvzvExr74mqlvc9DY3Bj65zQRadP/ax5qbN1/Pgx3Xpbbc2aM0+xsVX8HRpgymEYhuHvIPLy8gr6dBUqVFBISMh1zRce95gvwgICzs+ZM/0dAlDihBXDP5dvG7vBJ/N892Jnn8zjqRLxMKWQkBCP1h8AAGBHdm038O4GAABgqkRUEgAACGR2fRYGSQIAABazaY5AuwEAAJijkgAAgMWCguxZSiBJAADAYrQbAABAQKGSAACAxdjdAAAATNk0RyBJAADAanatJLAmAQAAmKKSAACAxexaSSBJAADAYjbNEWg3AAAAc1QSAACwGO0GAABgyqY5Au0GAABgjkoCAAAWo90AAABM2TRHoN0AAADMkSQAAGAxh8Phk+N6pKSkyOFwaNSoUR5fQ7sBAACL+bvdkJmZqXnz5unOO+/06joqCQAAWMyflYRffvlFDzzwgObPn6/y5ct7dS1JAgAANuFyuXTmzBm3w+VyXfGaESNGqGvXrurQoYPX9yNJAADAYg6Hb46UlBRFRka6HSkpKUXeNy0tTbt27briOVfCmgQAACzmq+ckJCUlafTo0W5jTqfT9Nwff/xRI0eO1AcffKCwsLBruh9JAgAANuF0OotMCi63c+dOHTt2TE2aNCkYy8/P19atWzVz5ky5XC4FBwdfcQ6SBAAALOaP3Q3t27fXV1995TY2YMAA3XHHHRo3btxVEwSJJAEAAMv547HM5cqVU/369d3GypQpo+jo6ELjRWHhIgAAMEUlAQAAi/n7YUqXbN682avzSRIAALCYXd8CSbsBAACYopIAAIDF7FpJIEkAAMBiNs0RSBIAALCaXSsJrEkAAACmqCQAAGAxmxYSSBIAALAa7QYAABBQqCQAAGAxmxYSSBIAALBakE2zBNoNAADAFJUEAAAsZtNCAkkCAABWs+vuBpIEAAAsFmTPHIE1CQAAwByVBAAALEa7AQAAmLJpjkC7AQAAmKOSAACAxRyyZymBJAEAAIuxuwEAAAQUKgkAAFiM3Q0AAMCUTXME2g0AAMAclQQAACxm11dFkyQAAGAxm+YIJAkAAFjNrgsXWZMAAABMUUkAAMBiNi0kkCQAAGA1uy5cpN0AAABMUUkAAMBi9qwjkCQAAGA5djcAAICAQiUBAACL2fVV0R4lCevWrfN4wu7du19zMAAABCK7ths8ShISExM9mszhcCg/P/964gEAACWER0nCxYsXrY4DAICAZdNCAmsSAACwWkC3Gy6Xm5urLVu26MiRI7pw4YLbZ0888YRPAgMAIFAE9MLFP9q9e7e6dOmiX3/9Vbm5uYqKilJOTo5Kly6tmJgYkgQAAAKE189JePLJJ9WtWzedPHlS4eHhysjI0A8//KAmTZropZdesiJGAABszeFw+OQobl4nCXv27NGYMWMUHBys4OBguVwuVa1aVdOmTdP48eOtiBEAAFtz+Ogobl4nCSEhIQXZTMWKFXXkyBFJUmRkZMF/AwAA+/N6TUJcXJx27Nih2rVrq23btpo4caJycnK0bNkyNWjQwIoYAQCwtRvmVdEvvPCCKleuLEmaPHmyoqOjNWzYMB07dkzz5s3zeYAAANidw+Gbo7h5XUlo2rRpwX/ffPPNWr9+vU8DAgAAJQMPUwIAwGI3zMOUatSoccUve/DgwesKCACAQGPTHMH7JGHUqFFuP+fl5Wn37t3asGGDxo4d66u4AACAn3mdJIwcOdJ0fNasWdqxY8d1BwQAQKDxx+6G1NRUpaam6vDhw5KkevXqaeLEiUpISPB4Dq93NxQlISFBq1ev9tV0AAAEDH/sbvjTn/6kKVOmaMeOHdqxY4fatWunHj16aO/evR7P4bOFi6tWrVJUVJSvpgMAIGD4Y+Fit27d3H7+xz/+odTUVGVkZKhevXoezXFND1P645c1DEPZ2dk6fvy4Zs+e7e10AADAQy6XSy6Xy23M6XTK6XRe8br8/Hz985//VG5uruLj4z2+n9dJQo8ePdyShKCgIN18881q06aN7rjjDm+ns8TPmTP9HQJQIpVv9pi/QwBKnHO7rf87w1e9/ZSUFD377LNuY8nJyZo0aZLp+V999ZXi4+N1/vx5lS1bVmvWrFHdunU9vp/DMAzjegIuic7/5u8IgJKJJAEorDiShCfW/ssn87yYUMOrSsKFCxd05MgRnTp1SqtXr9aCBQu0ZcsWjxMFrysJwcHBysrKUkxMjNv4iRMnFBMTo/z8fG+nBAAAHvCktfBHoaGhuvXWWyX9/sTkzMxMvfrqq5o7d65H13udJBRVeHC5XAoNDfV2OgAAAl5QCXmYkmEYhSoRV+JxkvDaa69J+n2F5oIFC1S2bNmCz/Lz87V169YSsyYBAICSxB9Jwvjx45WQkKCqVavq7NmzSktL0+bNm7VhwwaP5/A4SZg+fbqk37OQOXPmKDg4uOCz0NBQ3XLLLZozZ44X4QMAAKv89NNPeuihh5SVlaXIyEjdeeed2rBhgzp27OjxHB4nCYcOHZIktW3bVm+//bbKly/vfcQAANyA/PGchIULF173HF6vSfj444+v+6YAANxISsqaBG95vXWzV69emjJlSqHxF198Ub179/ZJUAAAwP+8ThK2bNmirl27Fhrv3Lmztm7d6pOgAAAIJP54d4MveN1u+OWXX0y3OoaEhOjMmTM+CQoAgEDij7dA+oLXlYT69etrxYoVhcbT0tK8etQjAAA3iiAfHcXN60rCM888o549e+rAgQNq166dJOmjjz7SW2+9pVWrVvk8QAAA4B9eJwndu3fX2rVr9cILL2jVqlUKDw9Xw4YNtWnTJkVERFgRIwAAtmbTboP3SYIkde3atWDx4qlTp/Tmm29q1KhR+uKLL3h3AwAAl7lh1iRcsmnTJj344IOKjY3VzJkz1aVLF+3YscOXsQEAAD/yqpJw9OhRLVmyRIsWLVJubq7uvfde5eXlafXq1SxaBACgCDYtJHheSejSpYvq1q2rffv2acaMGfrPf/6jGTNmWBkbAAABIcjhm6O4eVxJ+OCDD/TEE09o2LBhuu2226yMCQAAlAAeVxK2bdums2fPqmnTpmrRooVmzpyp48ePWxkbAAABIcjh8MlR7HF7emJ8fLzmz5+vrKwsPfLII0pLS1OVKlV08eJFbdy4UWfPnrUyTgAAbMuuj2X2endD6dKlNXDgQH3yySf66quvNGbMGE2ZMkUxMTHq3r27FTECAAA/uK6nPN5+++2aNm2ajh49quXLl/sqJgAAAkrAL1y8kuDgYCUmJioxMdEX0wEAEFAcsuceSJ8kCQAAoGj+qAL4gj9eKgUAAGyASgIAABazayWBJAEAAIs5bPpcZtoNAADAFJUEAAAsRrsBAACYsmm3gXYDAAAwRyUBAACL+ePlTL5AkgAAgMXsuiaBdgMAADBFJQEAAIvZtNtAkgAAgNWCeMETAAAwY9dKAmsSAACAKSoJAABYzK67G0gSAACwmF2fk0C7AQAAmKKSAACAxWxaSCBJAADAarQbAABAQKGSAACAxWxaSCBJAADAanYt29s1bgAAYDEqCQAAWMxh034DSQIAABazZ4pAkgAAgOXYAgkAAAIKlQQAACxmzzoCSQIAAJazabeBdgMAADBHJQEAAIuxBRIAAJiya9nernEDAIArSElJUbNmzVSuXDnFxMQoMTFR33zzjVdzkCQAAGAxh8Phk8MbW7Zs0YgRI5SRkaGNGzfqt99+U6dOnZSbm+vxHLQbAACwmD9WJGzYsMHt58WLFysmJkY7d+7U3Xff7dEcVBIAALgBnD59WpIUFRXl8TVUEgAAsJivdje4XC65XC63MafTKafTecXrDMPQ6NGj9Ze//EX169f3+H5UEgAAsFiQj46UlBRFRka6HSkpKVe9/2OPPaYvv/xSy5cv9ypuh2EYhldX2MD53/wdAVAylW/2mL9DAEqcc7tnWn6PNV9m+2SeLreX97qS8Pjjj2vt2rXaunWratSo4dX9aDcAAGATnrQWLjEMQ48//rjWrFmjzZs3e50gSCQJAABYzh+7G0aMGKG33npL//u//6ty5copO/v3akZkZKTCw8M9moM1CQAAWMzh8M3hjdTUVJ0+fVpt2rRR5cqVC44VK1Z4PAeVBAAAApAvlhySJAAAYLEgvzQcrh9JAgAAFrPpSyBZkwAAAMxRSQAAwGIO2g0AAMAM7QYAABBQqCQAAGAxdjcAAABTdm03kCQAAGAxuyYJrEkAAACmqCQAAGAxtkACAABTQfbMEWg3AAAAc1QSAACwGO0GAABgit0NAAAgoFBJAADAYrQbAACAKXY3AACAgEKSAMusWP6mEjq1U7O4Burb+2/atXOHv0MC/Cr25kgtev5hHf14qk6kv6yMtL8rrk5Vf4eFYuDw0f+KG+0GWGLD++s1bUqKJjyTrEZxjbVqZZqGPzJEa9a9p8qxsf4ODyh2N5UL16Ylo7Ul8zslPjZbx06eVc2qFXTq7Dl/h4ZiYNfdDSQJsMSypYv115499bdevSVJTydNUHr6J1q5YrlGPjnGz9EBxW/MgI46mv2zHpn0RsHYkayTfowIxcmmOQLtBvhe3oUL2r9vr+Jb/sVtPL7lXfpiz24/RQX4V9fWDbRr3xG9OW2gfvgoRduXj9OAv7b0d1jAFZXoJOHHH3/UwIEDr3iOy+XSmTNn3A6Xy1VMEcLMz6d+Vn5+vqKjo93Go6MrKCfnuJ+iAvyrRpUKGtK7lb4/clzdh8/SglWf6H+e7qX772nu79BQDIIcDp8cxR53sd/RCydPntTSpUuveE5KSooiIyPdjhenphRThLgSx2X/hzYMo9AYcKMICnJoz79+VPLMd/TFN0e1cPWnWrwmXUN7t/J3aCgGDh8dxc2vaxLWrVt3xc8PHjx41TmSkpI0evRotzEj2HldceH6lL+pvIKDg5WTk+M2fvLkCUVHV/BTVIB/Zeec0f6D2W5j/zqUrcT2jfwTEOABvyYJiYmJcjgcMgyjyHOu9i9Pp9Mpp9M9KTj/m0/CwzUKCQ1Vnbr1lJH+qdp36FgwnpGerjbt2vsxMsB/tu85qNrVY9zGbqsWw+LFG4VNi6h+bTdUrlxZq1ev1sWLF02PXbt2+TM8XIeH+g3Q26tXac3bq3TwwAG9OOUFZWVlqXefvv4ODfCLGW9sUvMGNTR2YCfVrFpBfTo31cCed2nuiq3+Dg3FgOckXIMmTZpo165dSkxMNP38alUGlFydE7ro9KmfNS91to4fP6Zbb6utWXPmKTa2ir9DA/xi574j6jNmvp57vLvGD03Q4X+f0NgXVyvtfR4yhpLLYfjxb+Ft27YpNzdXnTt3Nv08NzdXO3bsUOvWrb2al3YDYK58s8f8HQJQ4pzbPdPye3x+8LRP5mleM9In83jKr5WEVq2uvKq3TJkyXicIAACUNDZdklCyt0ACAAD/4bHMAABYzaalBJIEAAAs5o+dCb5AkgAAgMXs+rBZ1iQAAABTVBIAALCYTQsJJAkAAFjOplkC7QYAAGCKSgIAABZjdwMAADDF7gYAABBQqCQAAGAxmxYSSBIAALCcTbME2g0AAMAUlQQAACzG7gYAAGDKrrsbSBIAALCYTXME1iQAAABzVBIAALCaTUsJJAkAAFjMrgsXaTcAABCgtm7dqm7duik2NlYOh0Nr16716nqSBAAALOZw+ObwVm5urho2bKiZM2deU9y0GwAAsJi/mg0JCQlKSEi45utJEgAAsAmXyyWXy+U25nQ65XQ6Lbkf7QYAAKzm8M2RkpKiyMhItyMlJcWysKkkAABgMV/tbkhKStLo0aPdxqyqIkgkCQAA2IaVrQUzJAkAAFiMdzcAAABT/soRfvnlF33//fcFPx86dEh79uxRVFSUqlWrdtXrSRIAALCan7KEHTt2qG3btgU/X1rP0K9fPy1ZsuSq15MkAAAQoNq0aSPDMK75epIEAAAsZtd3N5AkAABgMbsuXORhSgAAwBSVBAAALGbTQgJJAgAAlrNplkC7AQAAmKKSAACAxdjdAAAATLG7AQAABBQqCQAAWMymhQSSBAAALGfTLIEkAQAAi9l14SJrEgAAgCkqCQAAWMyuuxtIEgAAsJhNcwTaDQAAwByVBAAALEa7AQAAFMGeWQLtBgAAYIpKAgAAFqPdAAAATNk0R6DdAAAAzFFJAADAYrQbAACAKbu+u4EkAQAAq9kzR2BNAgAAMEclAQAAi9m0kECSAACA1ey6cJF2AwAAMEUlAQAAi7G7AQAAmLNnjkC7AQAAmKOSAACAxWxaSCBJAADAauxuAAAAAYVKAgAAFmN3AwAAMEW7AQAABBSSBAAAYIp2AwAAFrNru4EkAQAAi9l14SLtBgAAYIpKAgAAFqPdAAAATNk0R6DdAAAAzFFJAADAajYtJZAkAABgMXY3AACAgEIlAQAAi7G7AQAAmLJpjkC7AQAAyzl8dFyD2bNnq0aNGgoLC1OTJk20bds2j68lSQAAIECtWLFCo0aN0oQJE7R79261atVKCQkJOnLkiEfXOwzDMCyOsdid/83fEQAlU/lmj/k7BKDEObd7pvX3yPPNPOEh3p3fokULNW7cWKmpqQVjderUUWJiolJSUq56PZUEAAAs5nD45vDGhQsXtHPnTnXq1MltvFOnTkpPT/doDhYuAgBgEy6XSy6Xy23M6XTK6XQWOjcnJ0f5+fmqWLGi23jFihWVnZ3t0f0CMkkIC8hvZT8ul0spKSlKSkoy/T8wil9xlFVxdfzZuPH46u+lSc+n6Nlnn3UbS05O1qRJk4q8xnFZCcIwjEJjRV4biGsSUDKcOXNGkZGROn36tCIiIvwdDlBi8GcD18qbSsKFCxdUunRp/fOf/9Rf//rXgvGRI0dqz5492rJly1Xvx5oEAABswul0KiIiwu0oqhoVGhqqJk2aaOPGjW7jGzduVMuWLT26H4V5AAAC1OjRo/XQQw+padOmio+P17x583TkyBE9+uijHl1PkgAAQIDq06ePTpw4oeeee05ZWVmqX7++1q9fr+rVq3t0PUkCLON0OpWcnMzCLOAy/NlAcRo+fLiGDx9+TdeycBEAAJhi4SIAADBFkgAAAEyRJAAAAFMkCQAAwBRJAixzPe8wBwLR1q1b1a1bN8XGxsrhcGjt2rX+Dgm4IpIEWOJ632EOBKLc3Fw1bNhQM2fyDg3YA1sgYYnrfYc5EOgcDofWrFmjxMREf4cCFIlKAnzOF+8wBwD4H0kCfM4X7zAHAPgfSQIscz3vMAcA+B9JAnyuQoUKCg4OLlQ1OHbsWKHqAgCg5CJJgM/54h3mAAD/4y2QsMT1vsMcCES//PKLvv/++4KfDx06pD179igqKkrVqlXzY2SAObZAwjKzZ8/WtGnTCt5hPn36dN19993+Dgvwm82bN6tt27aFxvv166clS5YUf0DAVZAkAAAAU6xJAAAApkgSAACAKZIEAABgiiQBAACYIkkAAACmSBIAAIApkgQAAGCKJAEIQJMmTVKjRo0Kfu7fv78SExOLPY7Dhw/L4XBoz549xX5vANePJAEoRv3795fD4ZDD4VBISIhq1qypp556Srm5uZbe99VXX/X4iX78xQ7gEt7dABSzzp07a/HixcrLy9O2bds0ePBg5ebmKjU11e28vLw8hYSE+OSekZGRPpkHwI2FSgJQzJxOpypVqqSqVavq/vvv1wMPPKC1a9cWtAgWLVqkmjVryul0yjAMnT59WkOHDlVMTIwiIiLUrl07ffHFF25zTpkyRRUrVlS5cuU0aNAgnT9/3u3zy9sNFy9e1NSpU3XrrbfK6XSqWrVq+sc//iFJqlGjhiQpLi5ODodDbdq0Kbhu8eLFqlOnjsLCwnTHHXdo9uzZbvf5/PPPFRcXp7CwMDVt2lS7d+/24W8OQHGjkgD4WXh4uPLy8iRJ33//vVauXKnVq1crODhYktS1a1dFRUVp/fr1ioyM1Ny5c9W+fXt9++23ioqK0sqVK5WcnKxZs2apVatWWrZsmV577TXVrFmzyHsmJSVp/vz5mj59uv7yl78oKytL//rXvyT9/hd98+bN9eGHH6pevXoKDQ2VJM2fP1/JycmaOXOm4uLitHv3bg0ZMkRlypRRv379lJubq3vuuUft2rXTG2+8oUOHDmnkyJEW//YAWMoAUGz69etn9OjRo+Dnzz77zIiOjjbuvfdeIzk52QgJCTGOHTtW8PlHH31kREREGOfPn3ebp1atWsbcuXMNwzCM+Ph449FHH3X7vEWLFkbDhg1N73vmzBnD6XQa8+fPN43x0KFDhiRj9+7dbuNVq1Y13nrrLbexyZMnG/Hx8YZhGMbcuXONqKgoIzc3t+Dz1NRU07kA2APtBqCYvfvuuypbtqzCwsIUHx+vu+++WzNmzJAkVa9eXTfffHPBuTt37tQvv/yi6OholS1btuA4dOiQDhw4IEnav3+/4uPj3e5x+c9/tH//frlcLrVv397jmI8fP64ff/xRgwYNcovj+eefd4ujYcOGKl26tEdxACj5aDcAxaxt27ZKTU1VSEiIYmNj3RYnlilTxu3cixcvqnLlytq8eXOheW666aZrun94eLjX11y8eFHS7y2HFi1auH12qS1i8NZ5IOCQJADFrEyZMrr11ls9Ordx48bKzs5WqVKldMstt5ieU6dOHWVkZOjhhx8uGMvIyChyzttuu03h4eH66KOPNHjw4EKfX1qDkJ+fXzBWsWJFValSRQcPHtQDDzxgOm/dunW1bNkynTt3riARuVIcAEo+2g1ACdahQwfFx8crMTFR//d//6fDhw8rPT1d//3f/60dO3ZIkkaOHKlFixZp0aJF+vbbb5WcnKy9e/cWOWdYWJjGjRunp59+Wq+//roOHDigjIwMLVy4UJIUExOj8PBwbdiwQT/99JNOnz4t6fcHNKWkpOjVV1/Vt99+q6+++kqLFy/Wyy+/LEm6//77FRQUpEGDBmnfvn1av369XnrpJYt/QwCsRJIAlGAOh0Pr16/X3XffrYEDB6p27drq27evDh8+rIoVK0qS+vTpo4kTJ2rcuHFq0qSJfvjhBw0bNuyK8z7zzDMaM2aMJk6cqDp16qhPnz46duyYJKlUqVJ67bXXNHfuXMXGxqpHjx6SpMGDB2vBggVasmSJGjRooNatW2vJkiUFWybLli2rd955R/v27VNcXJwmTJigqVOnWvjbAWA1h0EjEQAAmKCSAAAATJEkAAAAUyQJAADAFEkCAAAwRZIAAABMkSQAAABTJAkAAMAUSQIAADBFkgAAAEyRJAAAAFMkCQAAwBRJAgAAMPX/AfiQkgiVFlocAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['../models/stacking_classifier_2024-08-20_08-56-23.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the base models with pipelines\n",
    "base_models = [\n",
    "    ('lr', Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=1000, random_state=42))])),\n",
    "    ('rf', Pipeline([('clf', RandomForestClassifier(random_state=42))])),\n",
    "    ('svm', Pipeline([('scaler', StandardScaler()), ('clf', SVC(random_state=42))])),\n",
    "    ('gb', Pipeline([('clf', GradientBoostingClassifier(random_state=42))])),\n",
    "    ('xgb', Pipeline([('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))])),\n",
    "    ('mlp', Pipeline([('scaler', StandardScaler()), ('clf', MLPClassifier(random_state=42, max_iter=500))]))\n",
    "]\n",
    "\n",
    "# Define the meta-model with polynomial features\n",
    "meta_model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Stacking Classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Train and evaluate the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Stacking Classifier Model\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Cross-Validation for Stacking Classifier\n",
    "cv_scores = cross_val_score(stacking_clf, X_res, y_res, cv=StratifiedKFold(5))\n",
    "print(f\"Cross-Validation Accuracy for Stacking Classifier: {cv_scores.mean()} ± {cv_scores.std()}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Save the stacking classifier\n",
    "joblib.dump(stacking_clf, f'../models/stacking_classifier_{date_time}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking 3\n",
    "* Polynomial features\n",
    "+ Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 08:56:45,097] A new study created in memory with name: no-name-783e5559-981a-4518-a72f-05b77fa4542e\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:45,863] Trial 0 finished with value: 0.96 and parameters: {'C': 0.002665869956770616, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:46,628] Trial 1 finished with value: 0.96 and parameters: {'C': 0.04200033932562841, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:47,441] Trial 2 finished with value: 0.96 and parameters: {'C': 2.1459246152145764e-05, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:48,198] Trial 3 finished with value: 0.96 and parameters: {'C': 0.012283273188207225, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:48,933] Trial 4 finished with value: 0.96 and parameters: {'C': 0.0850756906372387, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:49,673] Trial 5 finished with value: 0.96 and parameters: {'C': 0.0005703195254224952, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:50,380] Trial 6 finished with value: 0.96 and parameters: {'C': 0.03535845352618068, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:51,118] Trial 7 finished with value: 0.96 and parameters: {'C': 25.12603695347059, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:51,871] Trial 8 finished with value: 0.96 and parameters: {'C': 0.7591887033797697, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:52,594] Trial 9 finished with value: 0.96 and parameters: {'C': 7.942328120658416, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:53,421] Trial 10 finished with value: 0.96 and parameters: {'C': 0.0006713282814223578, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:54,230] Trial 11 finished with value: 0.96 and parameters: {'C': 0.0015179011121324063, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:54,971] Trial 12 finished with value: 0.96 and parameters: {'C': 0.4797378748638857, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:55,685] Trial 13 finished with value: 0.96 and parameters: {'C': 1.6232667782906472e-05, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:56,405] Trial 14 finished with value: 0.96 and parameters: {'C': 0.004599594388716256, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:57,265] Trial 15 finished with value: 0.96 and parameters: {'C': 0.0001577357744981217, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:58,008] Trial 16 finished with value: 0.96 and parameters: {'C': 0.1723744440332161, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:58,736] Trial 17 finished with value: 0.96 and parameters: {'C': 3.6611853090735726, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:56:59,509] Trial 18 finished with value: 0.96 and parameters: {'C': 0.006716839132447174, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:00,303] Trial 19 finished with value: 0.96 and parameters: {'C': 0.00010109319621581972, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:01,051] Trial 20 finished with value: 0.96 and parameters: {'C': 0.017219738775075745, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:01,793] Trial 21 finished with value: 0.96 and parameters: {'C': 1.1366061275556924e-05, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:02,551] Trial 22 finished with value: 0.96 and parameters: {'C': 6.378805333811503e-05, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:03,282] Trial 23 finished with value: 0.96 and parameters: {'C': 0.0026003978325422946, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:04,050] Trial 24 finished with value: 0.96 and parameters: {'C': 0.00033931705533428447, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:04,792] Trial 25 finished with value: 0.96 and parameters: {'C': 90.28599464951182, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:05,557] Trial 26 finished with value: 0.96 and parameters: {'C': 3.68425535328504e-05, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:06,305] Trial 27 finished with value: 0.96 and parameters: {'C': 0.06879408149421151, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:07,072] Trial 28 finished with value: 0.96 and parameters: {'C': 1.1842937745272637, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:07,872] Trial 29 finished with value: 0.96 and parameters: {'C': 0.01797312292874116, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:08,667] Trial 30 finished with value: 0.96 and parameters: {'C': 0.0014997116269742775, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:09,388] Trial 31 finished with value: 0.96 and parameters: {'C': 0.09379177097429363, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:10,188] Trial 32 finished with value: 0.96 and parameters: {'C': 0.010145391549496927, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:10,939] Trial 33 finished with value: 0.96 and parameters: {'C': 0.23604552041528928, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:11,661] Trial 34 finished with value: 0.96 and parameters: {'C': 0.03599123227340703, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:12,402] Trial 35 finished with value: 0.96 and parameters: {'C': 0.0003225507427948005, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:13,151] Trial 36 finished with value: 0.96 and parameters: {'C': 0.04599303402297192, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:13,902] Trial 37 finished with value: 0.96 and parameters: {'C': 0.0008822686298817627, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:14,642] Trial 38 finished with value: 0.96 and parameters: {'C': 0.004429511335932946, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:15,391] Trial 39 finished with value: 0.96 and parameters: {'C': 0.017000979449753366, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:16,098] Trial 40 finished with value: 0.96 and parameters: {'C': 1.7179655585905094, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:16,836] Trial 41 finished with value: 0.96 and parameters: {'C': 0.34014926484832547, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:17,591] Trial 42 finished with value: 0.96 and parameters: {'C': 0.1441960786793143, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:18,308] Trial 43 finished with value: 0.96 and parameters: {'C': 0.02863304341987777, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:19,030] Trial 44 finished with value: 0.96 and parameters: {'C': 0.6067982709654017, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:19,791] Trial 45 finished with value: 0.96 and parameters: {'C': 0.0029705889434130223, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:20,609] Trial 46 finished with value: 0.96 and parameters: {'C': 0.007728198149531842, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:21,355] Trial 47 finished with value: 0.96 and parameters: {'C': 11.330461596065643, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:22,218] Trial 48 finished with value: 0.96 and parameters: {'C': 2.2275709252179207e-05, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-20 08:57:22,987] Trial 49 finished with value: 0.96 and parameters: {'C': 0.08282724762740172, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.96.\n",
      "[I 2024-08-20 08:57:22,988] A new study created in memory with name: no-name-f4175bc1-d325-4d0e-a790-f20469cd8aa9\n",
      "[I 2024-08-20 08:57:24,483] Trial 0 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 196, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:25,009] Trial 1 finished with value: 0.7977777777777777 and parameters: {'n_estimators': 68, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:26,264] Trial 2 finished with value: 0.7977777777777777 and parameters: {'n_estimators': 164, 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:27,433] Trial 3 finished with value: 0.7977777777777777 and parameters: {'n_estimators': 147, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:28,296] Trial 4 finished with value: 0.8577777777777778 and parameters: {'n_estimators': 109, 'max_depth': 18, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:28,717] Trial 5 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 56, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:29,428] Trial 6 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 91, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:30,856] Trial 7 finished with value: 0.7755555555555554 and parameters: {'n_estimators': 200, 'max_depth': 11, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:31,809] Trial 8 finished with value: 0.7977777777777777 and parameters: {'n_estimators': 130, 'max_depth': 21, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:33,127] Trial 9 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 195, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:34,261] Trial 10 finished with value: 0.8577777777777778 and parameters: {'n_estimators': 168, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:34,991] Trial 11 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 94, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:35,604] Trial 12 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 80, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:36,452] Trial 13 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 118, 'max_depth': 25, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:37,206] Trial 14 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 94, 'max_depth': 27, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:38,149] Trial 15 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 136, 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:39,412] Trial 16 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 176, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:40,155] Trial 17 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 104, 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:41,257] Trial 18 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 151, 'max_depth': 23, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:42,526] Trial 19 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 183, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:43,089] Trial 20 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 74, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:43,699] Trial 21 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 86, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:44,368] Trial 22 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 96, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:44,744] Trial 23 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 52, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:45,590] Trial 24 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 117, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:46,160] Trial 25 finished with value: 0.8399999999999999 and parameters: {'n_estimators': 65, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:46,842] Trial 26 finished with value: 0.8577777777777778 and parameters: {'n_estimators': 92, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:47,803] Trial 27 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 105, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:48,779] Trial 28 finished with value: 0.7955555555555555 and parameters: {'n_estimators': 136, 'max_depth': 29, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:49,323] Trial 29 finished with value: 0.7977777777777777 and parameters: {'n_estimators': 67, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:50,200] Trial 30 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 120, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:50,851] Trial 31 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 82, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:51,482] Trial 32 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 82, 'max_depth': 25, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:52,140] Trial 33 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 70, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:52,763] Trial 34 finished with value: 0.86 and parameters: {'n_estimators': 78, 'max_depth': 29, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:53,891] Trial 35 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 153, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:54,424] Trial 36 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 58, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:55,208] Trial 37 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 99, 'max_depth': 21, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:56,045] Trial 38 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 110, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:56,778] Trial 39 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 87, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:57,919] Trial 40 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 162, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:57:59,227] Trial 41 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 193, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:58:00,493] Trial 42 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 176, 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:58:01,888] Trial 43 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 192, 'max_depth': 29, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:58:03,218] Trial 44 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 183, 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:58:04,487] Trial 45 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 170, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:58:06,015] Trial 46 finished with value: 0.8577777777777778 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:58:07,184] Trial 47 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 159, 'max_depth': 22, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:58:08,489] Trial 48 finished with value: 0.8577777777777778 and parameters: {'n_estimators': 184, 'max_depth': 25, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:58:09,398] Trial 49 finished with value: 0.8177777777777777 and parameters: {'n_estimators': 130, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:58:09,400] A new study created in memory with name: no-name-8f96e92f-3362-4364-aa9f-3bb64fded591\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:09,446] Trial 0 finished with value: 0.6377777777777778 and parameters: {'C': 0.0336866155950383, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6377777777777778.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:09,489] Trial 1 finished with value: 0.7733333333333333 and parameters: {'C': 1.873504575861021, 'kernel': 'linear'}. Best is trial 1 with value: 0.7733333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:09,534] Trial 2 finished with value: 0.6377777777777778 and parameters: {'C': 0.014859856260948736, 'kernel': 'rbf'}. Best is trial 1 with value: 0.7733333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:09,576] Trial 3 finished with value: 0.7911111111111111 and parameters: {'C': 0.013811001239768337, 'kernel': 'linear'}. Best is trial 3 with value: 0.7911111111111111.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:09,625] Trial 4 finished with value: 0.6844444444444445 and parameters: {'C': 0.06706122100165075, 'kernel': 'linear'}. Best is trial 3 with value: 0.7911111111111111.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:09,675] Trial 5 finished with value: 0.7711111111111111 and parameters: {'C': 0.30789634424156787, 'kernel': 'rbf'}. Best is trial 3 with value: 0.7911111111111111.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:09,720] Trial 6 finished with value: 0.8333333333333333 and parameters: {'C': 0.012660316969373543, 'kernel': 'linear'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:09,769] Trial 7 finished with value: 0.8133333333333332 and parameters: {'C': 1.5641822875347111, 'kernel': 'rbf'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:09,816] Trial 8 finished with value: 0.7711111111111111 and parameters: {'C': 0.21122523445938926, 'kernel': 'linear'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:09,860] Trial 9 finished with value: 0.6377777777777778 and parameters: {'C': 0.039088802064484146, 'kernel': 'rbf'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:09,915] Trial 10 finished with value: 0.6377777777777778 and parameters: {'C': 0.0010831893395473837, 'kernel': 'linear'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:09,971] Trial 11 finished with value: 0.7955555555555555 and parameters: {'C': 70.15047537922334, 'kernel': 'rbf'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,025] Trial 12 finished with value: 0.7733333333333333 and parameters: {'C': 6.999619494506983, 'kernel': 'linear'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,077] Trial 13 finished with value: 0.6377777777777778 and parameters: {'C': 0.0018454246184760128, 'kernel': 'rbf'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,133] Trial 14 finished with value: 0.7733333333333333 and parameters: {'C': 2.2034740686760297, 'kernel': 'linear'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,182] Trial 15 finished with value: 0.7955555555555555 and parameters: {'C': 7.750035385887357, 'kernel': 'rbf'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,235] Trial 16 finished with value: 0.7288888888888889 and parameters: {'C': 0.0037592032367595872, 'kernel': 'linear'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,286] Trial 17 finished with value: 0.7955555555555555 and parameters: {'C': 60.69412975775043, 'kernel': 'rbf'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,340] Trial 18 finished with value: 0.7911111111111111 and parameters: {'C': 1.032009674359093, 'kernel': 'rbf'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,392] Trial 19 finished with value: 0.7488888888888888 and parameters: {'C': 0.119958143531577, 'kernel': 'linear'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,443] Trial 20 finished with value: 0.8133333333333332 and parameters: {'C': 0.6698674644285726, 'kernel': 'linear'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,495] Trial 21 finished with value: 0.8133333333333332 and parameters: {'C': 0.7822365788053653, 'kernel': 'linear'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,543] Trial 22 finished with value: 0.7333333333333332 and parameters: {'C': 4.889770702714488, 'kernel': 'linear'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,597] Trial 23 finished with value: 0.7133333333333333 and parameters: {'C': 17.81650640285617, 'kernel': 'linear'}. Best is trial 6 with value: 0.8333333333333333.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,651] Trial 24 finished with value: 0.8333333333333334 and parameters: {'C': 0.4718503106061419, 'kernel': 'linear'}. Best is trial 24 with value: 0.8333333333333334.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,703] Trial 25 finished with value: 0.7488888888888888 and parameters: {'C': 0.006690827396885506, 'kernel': 'linear'}. Best is trial 24 with value: 0.8333333333333334.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,761] Trial 26 finished with value: 0.7044444444444444 and parameters: {'C': 0.155115972260745, 'kernel': 'rbf'}. Best is trial 24 with value: 0.8333333333333334.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,814] Trial 27 finished with value: 0.8133333333333332 and parameters: {'C': 0.6268996507992528, 'kernel': 'linear'}. Best is trial 24 with value: 0.8333333333333334.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,873] Trial 28 finished with value: 0.8555555555555555 and parameters: {'C': 2.4599407689599677, 'kernel': 'rbf'}. Best is trial 28 with value: 0.8555555555555555.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,926] Trial 29 finished with value: 0.8399999999999999 and parameters: {'C': 22.809081177599747, 'kernel': 'rbf'}. Best is trial 28 with value: 0.8555555555555555.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:10,978] Trial 30 finished with value: 0.8399999999999999 and parameters: {'C': 27.912401439992305, 'kernel': 'rbf'}. Best is trial 28 with value: 0.8555555555555555.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,032] Trial 31 finished with value: 0.8399999999999999 and parameters: {'C': 29.449882302986882, 'kernel': 'rbf'}. Best is trial 28 with value: 0.8555555555555555.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,084] Trial 32 finished with value: 0.8399999999999999 and parameters: {'C': 27.989376880312417, 'kernel': 'rbf'}. Best is trial 28 with value: 0.8555555555555555.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,134] Trial 33 finished with value: 0.8399999999999999 and parameters: {'C': 25.746576040942877, 'kernel': 'rbf'}. Best is trial 28 with value: 0.8555555555555555.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,191] Trial 34 finished with value: 0.8177777777777777 and parameters: {'C': 13.447688410233512, 'kernel': 'rbf'}. Best is trial 28 with value: 0.8555555555555555.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,240] Trial 35 finished with value: 0.7955555555555555 and parameters: {'C': 48.00485688455316, 'kernel': 'rbf'}. Best is trial 28 with value: 0.8555555555555555.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,289] Trial 36 finished with value: 0.8755555555555556 and parameters: {'C': 3.322429988483555, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,340] Trial 37 finished with value: 0.8755555555555556 and parameters: {'C': 3.3676251687130856, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,394] Trial 38 finished with value: 0.8755555555555556 and parameters: {'C': 2.766796169702494, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,445] Trial 39 finished with value: 0.8755555555555556 and parameters: {'C': 3.341849853792236, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,494] Trial 40 finished with value: 0.8755555555555556 and parameters: {'C': 3.595434665093707, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,546] Trial 41 finished with value: 0.8355555555555556 and parameters: {'C': 4.288562181712288, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,594] Trial 42 finished with value: 0.8755555555555556 and parameters: {'C': 3.5639583393639684, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,643] Trial 43 finished with value: 0.8133333333333332 and parameters: {'C': 1.446079494137751, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,695] Trial 44 finished with value: 0.8377777777777776 and parameters: {'C': 10.736322728565547, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,749] Trial 45 finished with value: 0.8755555555555556 and parameters: {'C': 2.9674233407831805, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,797] Trial 46 finished with value: 0.8133333333333332 and parameters: {'C': 1.464650330426178, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,850] Trial 47 finished with value: 0.7711111111111111 and parameters: {'C': 0.3438358420799858, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,899] Trial 48 finished with value: 0.7955555555555555 and parameters: {'C': 7.344235680240312, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-20 08:58:11,948] Trial 49 finished with value: 0.7955555555555555 and parameters: {'C': 5.454316453563188, 'kernel': 'rbf'}. Best is trial 36 with value: 0.8755555555555556.\n",
      "[I 2024-08-20 08:58:11,949] A new study created in memory with name: no-name-94b58149-6335-4c48-829e-b657eddef1da\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:12,706] Trial 0 finished with value: 0.86 and parameters: {'n_estimators': 155, 'learning_rate': 0.004932013902167889, 'max_depth': 4}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:13,354] Trial 1 finished with value: 0.86 and parameters: {'n_estimators': 118, 'learning_rate': 0.002310863491225813, 'max_depth': 7}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:14,119] Trial 2 finished with value: 0.86 and parameters: {'n_estimators': 147, 'learning_rate': 0.02796012467459576, 'max_depth': 6}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:14,495] Trial 3 finished with value: 0.86 and parameters: {'n_estimators': 76, 'learning_rate': 0.05661685787988876, 'max_depth': 7}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:14,807] Trial 4 finished with value: 0.8577777777777778 and parameters: {'n_estimators': 61, 'learning_rate': 0.0103759728234541, 'max_depth': 5}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:15,105] Trial 5 finished with value: 0.86 and parameters: {'n_estimators': 57, 'learning_rate': 0.015340451191350263, 'max_depth': 9}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:15,561] Trial 6 finished with value: 0.86 and parameters: {'n_estimators': 84, 'learning_rate': 0.00117343029940146, 'max_depth': 10}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:16,310] Trial 7 finished with value: 0.86 and parameters: {'n_estimators': 137, 'learning_rate': 0.006388208333680727, 'max_depth': 4}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:17,064] Trial 8 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 149, 'learning_rate': 0.0014921019758656277, 'max_depth': 5}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:17,658] Trial 9 finished with value: 0.86 and parameters: {'n_estimators': 103, 'learning_rate': 0.0024930526297920626, 'max_depth': 6}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:18,576] Trial 10 finished with value: 0.86 and parameters: {'n_estimators': 193, 'learning_rate': 0.09941245792989703, 'max_depth': 3}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:19,421] Trial 11 finished with value: 0.86 and parameters: {'n_estimators': 177, 'learning_rate': 0.004066993342862057, 'max_depth': 8}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:19,913] Trial 12 finished with value: 0.8155555555555555 and parameters: {'n_estimators': 111, 'learning_rate': 0.003534334837147421, 'max_depth': 3}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:20,680] Trial 13 finished with value: 0.86 and parameters: {'n_estimators': 165, 'learning_rate': 0.0020347750371458584, 'max_depth': 7}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:21,279] Trial 14 finished with value: 0.86 and parameters: {'n_estimators': 121, 'learning_rate': 0.006315944145010795, 'max_depth': 8}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:22,124] Trial 15 finished with value: 0.86 and parameters: {'n_estimators': 162, 'learning_rate': 0.004793037133041668, 'max_depth': 5}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:22,858] Trial 16 finished with value: 0.86 and parameters: {'n_estimators': 132, 'learning_rate': 0.016710356411987565, 'max_depth': 4}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:23,437] Trial 17 finished with value: 0.86 and parameters: {'n_estimators': 107, 'learning_rate': 0.002554889033070118, 'max_depth': 8}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:24,461] Trial 18 finished with value: 0.86 and parameters: {'n_estimators': 196, 'learning_rate': 0.0010306974555537144, 'max_depth': 6}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:24,925] Trial 19 finished with value: 0.86 and parameters: {'n_estimators': 92, 'learning_rate': 0.008598590947750883, 'max_depth': 4}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:25,537] Trial 20 finished with value: 0.86 and parameters: {'n_estimators': 125, 'learning_rate': 0.0018790389247625324, 'max_depth': 10}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:26,270] Trial 21 finished with value: 0.86 and parameters: {'n_estimators': 147, 'learning_rate': 0.02793288214168641, 'max_depth': 6}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:27,123] Trial 22 finished with value: 0.86 and parameters: {'n_estimators': 155, 'learning_rate': 0.034388808333575195, 'max_depth': 7}. Best is trial 0 with value: 0.86.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:28,058] Trial 23 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 175, 'learning_rate': 0.01753731836825226, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:28,996] Trial 24 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 177, 'learning_rate': 0.014401217998235427, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:29,974] Trial 25 finished with value: 0.86 and parameters: {'n_estimators': 179, 'learning_rate': 0.015195553222780671, 'max_depth': 4}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:30,968] Trial 26 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 179, 'learning_rate': 0.009225998468123152, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:31,927] Trial 27 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 179, 'learning_rate': 0.011283771122263496, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:32,904] Trial 28 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 187, 'learning_rate': 0.022438977101575643, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:33,751] Trial 29 finished with value: 0.86 and parameters: {'n_estimators': 168, 'learning_rate': 0.048174858342917924, 'max_depth': 3}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:34,763] Trial 30 finished with value: 0.86 and parameters: {'n_estimators': 200, 'learning_rate': 0.007264404571366296, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:35,635] Trial 31 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 181, 'learning_rate': 0.009522121063638159, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:36,479] Trial 32 finished with value: 0.86 and parameters: {'n_estimators': 171, 'learning_rate': 0.012109909157921227, 'max_depth': 6}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:37,439] Trial 33 finished with value: 0.86 and parameters: {'n_estimators': 188, 'learning_rate': 0.01257781736562194, 'max_depth': 4}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:38,265] Trial 34 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 159, 'learning_rate': 0.0208710679152255, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:39,111] Trial 35 finished with value: 0.86 and parameters: {'n_estimators': 174, 'learning_rate': 0.02068937573081078, 'max_depth': 6}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:40,167] Trial 36 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 185, 'learning_rate': 0.03479697850113151, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:40,949] Trial 37 finished with value: 0.86 and parameters: {'n_estimators': 146, 'learning_rate': 0.011306894137615287, 'max_depth': 6}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:41,843] Trial 38 finished with value: 0.86 and parameters: {'n_estimators': 171, 'learning_rate': 0.007817582479675785, 'max_depth': 4}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:42,687] Trial 39 finished with value: 0.86 and parameters: {'n_estimators': 140, 'learning_rate': 0.016355273537560736, 'max_depth': 7}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:43,560] Trial 40 finished with value: 0.86 and parameters: {'n_estimators': 154, 'learning_rate': 0.005962722068876386, 'max_depth': 4}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:44,638] Trial 41 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 190, 'learning_rate': 0.021239703524887982, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:45,785] Trial 42 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 183, 'learning_rate': 0.02725642898340399, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:46,942] Trial 43 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 193, 'learning_rate': 0.012956292245017853, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:47,905] Trial 44 finished with value: 0.86 and parameters: {'n_estimators': 177, 'learning_rate': 0.04961790569066066, 'max_depth': 6}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:48,219] Trial 45 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 50, 'learning_rate': 0.010044973809847082, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:49,268] Trial 46 finished with value: 0.86 and parameters: {'n_estimators': 200, 'learning_rate': 0.018412014343126577, 'max_depth': 3}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:50,290] Trial 47 finished with value: 0.86 and parameters: {'n_estimators': 165, 'learning_rate': 0.02455662399130625, 'max_depth': 4}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:51,223] Trial 48 finished with value: 0.86 and parameters: {'n_estimators': 186, 'learning_rate': 0.07143133031911758, 'max_depth': 6}. Best is trial 23 with value: 0.8800000000000001.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:51,668] Trial 49 finished with value: 0.8800000000000001 and parameters: {'n_estimators': 74, 'learning_rate': 0.03400112074574516, 'max_depth': 5}. Best is trial 23 with value: 0.8800000000000001.\n",
      "[I 2024-08-20 08:58:51,670] A new study created in memory with name: no-name-de4657ef-cf07-4c43-a4ce-c755d8feb045\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:51,946] Trial 0 finished with value: 0.7955555555555555 and parameters: {'n_estimators': 117, 'learning_rate': 0.0025144140940512563, 'max_depth': 7}. Best is trial 0 with value: 0.7955555555555555.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:52,286] Trial 1 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 171, 'learning_rate': 0.007057490032370833, 'max_depth': 5}. Best is trial 1 with value: 0.8377777777777776.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:52,581] Trial 2 finished with value: 0.9 and parameters: {'n_estimators': 149, 'learning_rate': 0.042336148090466444, 'max_depth': 8}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:52,792] Trial 3 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 79, 'learning_rate': 0.014222016280656396, 'max_depth': 3}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:53,043] Trial 4 finished with value: 0.9 and parameters: {'n_estimators': 110, 'learning_rate': 0.06105320784028099, 'max_depth': 10}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:53,300] Trial 5 finished with value: 0.7955555555555555 and parameters: {'n_estimators': 101, 'learning_rate': 0.002440209849803231, 'max_depth': 6}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:53,589] Trial 6 finished with value: 0.9 and parameters: {'n_estimators': 160, 'learning_rate': 0.08837159176196385, 'max_depth': 5}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:53,821] Trial 7 finished with value: 0.7088888888888888 and parameters: {'n_estimators': 68, 'learning_rate': 0.0013155644760504685, 'max_depth': 10}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:54,185] Trial 8 finished with value: 0.9 and parameters: {'n_estimators': 166, 'learning_rate': 0.03543487347510949, 'max_depth': 10}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:54,487] Trial 9 finished with value: 0.9 and parameters: {'n_estimators': 153, 'learning_rate': 0.05997220378393929, 'max_depth': 6}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:54,935] Trial 10 finished with value: 0.8577777777777778 and parameters: {'n_estimators': 200, 'learning_rate': 0.023108756881474398, 'max_depth': 8}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:55,245] Trial 11 finished with value: 0.8777777777777779 and parameters: {'n_estimators': 136, 'learning_rate': 0.04213280152769659, 'max_depth': 9}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:55,554] Trial 12 finished with value: 0.9 and parameters: {'n_estimators': 105, 'learning_rate': 0.09998622479750137, 'max_depth': 8}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:55,819] Trial 13 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 88, 'learning_rate': 0.009246908607527244, 'max_depth': 9}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:56,141] Trial 14 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 133, 'learning_rate': 0.019130877592829266, 'max_depth': 9}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:56,327] Trial 15 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 55, 'learning_rate': 0.03484111206672204, 'max_depth': 8}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:56,687] Trial 16 finished with value: 0.9 and parameters: {'n_estimators': 182, 'learning_rate': 0.05266288715838843, 'max_depth': 10}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:57,084] Trial 17 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 147, 'learning_rate': 0.00544625563671252, 'max_depth': 7}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:57,381] Trial 18 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 121, 'learning_rate': 0.024498889154566085, 'max_depth': 9}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:57,649] Trial 19 finished with value: 0.9 and parameters: {'n_estimators': 102, 'learning_rate': 0.07756343483416567, 'max_depth': 3}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:57,997] Trial 20 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 140, 'learning_rate': 0.013506518515295501, 'max_depth': 8}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:58,338] Trial 21 finished with value: 0.9 and parameters: {'n_estimators': 162, 'learning_rate': 0.07292666289932782, 'max_depth': 4}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:58,697] Trial 22 finished with value: 0.9 and parameters: {'n_estimators': 190, 'learning_rate': 0.09876488719336513, 'max_depth': 5}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:59,071] Trial 23 finished with value: 0.9 and parameters: {'n_estimators': 152, 'learning_rate': 0.04831901148510312, 'max_depth': 5}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:59,418] Trial 24 finished with value: 0.8577777777777778 and parameters: {'n_estimators': 125, 'learning_rate': 0.03466058465986308, 'max_depth': 4}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:58:59,834] Trial 25 finished with value: 0.9 and parameters: {'n_estimators': 177, 'learning_rate': 0.06728893807618479, 'max_depth': 7}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:00,198] Trial 26 finished with value: 0.8577777777777778 and parameters: {'n_estimators': 159, 'learning_rate': 0.028656840217377095, 'max_depth': 6}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:00,468] Trial 27 finished with value: 0.8777777777777779 and parameters: {'n_estimators': 111, 'learning_rate': 0.05068566249183377, 'max_depth': 10}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:00,717] Trial 28 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 90, 'learning_rate': 0.018803328610604637, 'max_depth': 7}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:01,157] Trial 29 finished with value: 0.8155555555555555 and parameters: {'n_estimators': 143, 'learning_rate': 0.004824875045993663, 'max_depth': 4}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:01,436] Trial 30 finished with value: 0.9 and parameters: {'n_estimators': 129, 'learning_rate': 0.08327397898710825, 'max_depth': 7}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:01,881] Trial 31 finished with value: 0.9 and parameters: {'n_estimators': 169, 'learning_rate': 0.03635517187551257, 'max_depth': 10}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:02,269] Trial 32 finished with value: 0.9 and parameters: {'n_estimators': 165, 'learning_rate': 0.06085026608101576, 'max_depth': 9}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:02,667] Trial 33 finished with value: 0.8777777777777779 and parameters: {'n_estimators': 176, 'learning_rate': 0.030517547669563497, 'max_depth': 10}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:03,144] Trial 34 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 116, 'learning_rate': 0.04434004215912231, 'max_depth': 9}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:03,616] Trial 35 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 154, 'learning_rate': 0.014658515181467413, 'max_depth': 10}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:04,012] Trial 36 finished with value: 0.9 and parameters: {'n_estimators': 189, 'learning_rate': 0.062164714016495294, 'max_depth': 5}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:04,573] Trial 37 finished with value: 0.7955555555555555 and parameters: {'n_estimators': 170, 'learning_rate': 0.0022887701196325303, 'max_depth': 6}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:04,959] Trial 38 finished with value: 0.7088888888888888 and parameters: {'n_estimators': 147, 'learning_rate': 0.001055368433511786, 'max_depth': 8}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:05,352] Trial 39 finished with value: 0.9 and parameters: {'n_estimators': 158, 'learning_rate': 0.04151398440692666, 'max_depth': 10}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:05,623] Trial 40 finished with value: 0.9 and parameters: {'n_estimators': 94, 'learning_rate': 0.08458237260658522, 'max_depth': 8}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:05,927] Trial 41 finished with value: 0.9 and parameters: {'n_estimators': 137, 'learning_rate': 0.059813020379883404, 'max_depth': 6}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:06,287] Trial 42 finished with value: 0.9 and parameters: {'n_estimators': 149, 'learning_rate': 0.09873732006254514, 'max_depth': 5}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:06,542] Trial 43 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 73, 'learning_rate': 0.024171462572007495, 'max_depth': 6}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:06,903] Trial 44 finished with value: 0.9 and parameters: {'n_estimators': 164, 'learning_rate': 0.040834660824903155, 'max_depth': 9}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:07,291] Trial 45 finished with value: 0.9 and parameters: {'n_estimators': 183, 'learning_rate': 0.05481894709115049, 'max_depth': 6}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:07,619] Trial 46 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 132, 'learning_rate': 0.01932716519294066, 'max_depth': 5}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:07,889] Trial 47 finished with value: 0.9 and parameters: {'n_estimators': 112, 'learning_rate': 0.07125580992342324, 'max_depth': 9}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:08,217] Trial 48 finished with value: 0.8577777777777778 and parameters: {'n_estimators': 141, 'learning_rate': 0.029242699614865277, 'max_depth': 7}. Best is trial 2 with value: 0.9.\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_42352\\3569166741.py:52: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-20 08:59:08,593] Trial 49 finished with value: 0.8377777777777776 and parameters: {'n_estimators': 156, 'learning_rate': 0.008142608317465364, 'max_depth': 8}. Best is trial 2 with value: 0.9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier with Optimized Base Models\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "Cross-Validation Accuracy for Stacking Classifier: 1.0 ± 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['../models/stacking_classifier_optimized_2024-08-20_08-59-28.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the objective functions for each base model\n",
    "def objective_lr(trial):\n",
    "    param_grid = {\n",
    "        'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l2']),\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs']),\n",
    "    }\n",
    "    pipeline = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    return cross_val_score(pipeline, X_train, y_train, cv=StratifiedKFold(5)).mean()\n",
    "\n",
    "def objective_rf(trial):\n",
    "    param_grid = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 30),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n",
    "    }\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', RandomForestClassifier(random_state=42, **param_grid))\n",
    "    ])\n",
    "    return cross_val_score(pipeline, X_train, y_train, cv=StratifiedKFold(5)).mean()\n",
    "\n",
    "def objective_svm(trial):\n",
    "    param_grid = {\n",
    "        'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
    "        'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf']),\n",
    "    }\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', SVC(random_state=42, **param_grid))\n",
    "    ])\n",
    "    return cross_val_score(pipeline, X_train, y_train, cv=StratifiedKFold(5)).mean()\n",
    "\n",
    "def objective_gb(trial):\n",
    "    param_grid = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "    }\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', GradientBoostingClassifier(random_state=42, **param_grid))\n",
    "    ])\n",
    "    return cross_val_score(pipeline, X_train, y_train, cv=StratifiedKFold(5)).mean()\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    param_grid = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "    }\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', **param_grid))\n",
    "    ])\n",
    "    return cross_val_score(pipeline, X_train, y_train, cv=StratifiedKFold(5)).mean()\n",
    "\n",
    "# Run Optuna studies for each base model\n",
    "studies = {}\n",
    "for model_name, objective in zip(\n",
    "    ['LogisticRegression', 'RandomForest', 'SVM', 'GradientBoosting', 'XGBoost'],\n",
    "    [objective_lr, objective_rf, objective_svm, objective_gb, objective_xgb]\n",
    "):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    studies[model_name] = study.best_params\n",
    "\n",
    "# Define the optimized base models\n",
    "optimized_base_models = [\n",
    "    ('lr', Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=1000, random_state=42, **studies['LogisticRegression']))])),\n",
    "    ('rf', Pipeline([('clf', RandomForestClassifier(random_state=42, **studies['RandomForest']))])),\n",
    "    ('svm', Pipeline([('scaler', StandardScaler()), ('clf', SVC(random_state=42, **studies['SVM']))])),\n",
    "    ('gb', Pipeline([('clf', GradientBoostingClassifier(random_state=42, **studies['GradientBoosting']))])),\n",
    "    ('xgb', Pipeline([('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', **studies['XGBoost']))]))\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Stacking Classifier with optimized base models\n",
    "stacking_clf = StackingClassifier(estimators=optimized_base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Train and evaluate the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Stacking Classifier with Optimized Base Models\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Cross-Validation for Stacking Classifier\n",
    "cv_scores = cross_val_score(stacking_clf, X_res, y_res, cv=StratifiedKFold(5))\n",
    "print(f\"Cross-Validation Accuracy for Stacking Classifier: {cv_scores.mean()} ± {cv_scores.std()}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Save the stacking classifier\n",
    "date_time = pd.Timestamp.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "joblib.dump(stacking_clf, f'../models/stacking_classifier_optimized_{date_time}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOA8bdRDz91X"
   },
   "source": [
    "# Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "vrz5KfPsz-3Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Model\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Guill\\miniconda3\\envs\\happy-ml\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy for Stacking Classifier: 1.0 ± 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['stacking_classifier.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "base_models = [\n",
    "    ('lr', Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=1000, random_state=42))])),\n",
    "    ('rf', Pipeline([('clf', RandomForestClassifier(random_state=42))])),\n",
    "    ('svm', Pipeline([('scaler', StandardScaler()), ('clf', SVC(random_state=42))])),\n",
    "    ('gb', Pipeline([('clf', GradientBoostingClassifier(random_state=42))])),\n",
    "    ('xgb', Pipeline([('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))])),\n",
    "    ('mlp', Pipeline([('scaler', StandardScaler()), ('clf', MLPClassifier(random_state=42, max_iter=500))]))\n",
    "]\n",
    "\n",
    "# Define the meta-model with polynomial features\n",
    "meta_model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Stacking Classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Train and evaluate the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Stacking Classifier Model\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Cross-Validation for Stacking Classifier\n",
    "cv_scores = cross_val_score(stacking_clf, X_res, y_res, cv=StratifiedKFold(5))\n",
    "print(f\"Cross-Validation Accuracy for Stacking Classifier: {cv_scores.mean()} ± {cv_scores.std()}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Save the stacking classifier\n",
    "joblib.dump(stacking_clf, 'stacking_classifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
