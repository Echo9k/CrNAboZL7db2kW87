{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eM6m2JHf5q5"
   },
   "source": [
    "# Experiment with different classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to try\n",
    "\n",
    "1. Advanced Ensemble Techniques\n",
    "    - **Blending**: We’ll implement a blending technique where a meta-model is trained on a holdout set (a part of the training data not seen by the base models).\n",
    "    - **Bagging**: We’ll explore bagging, which involves training multiple instances of the same model on different subsets of the training data.\n",
    "\n",
    "2. Class Balancing Techniques\n",
    "    - **ADASYN**: We’ll experiment with the ADASYN technique for generating synthetic samples to balance the classes.\n",
    "    - **Class Weighting**: In some algorithms like Logistic Regression or SVM, we can assign weights to classes inversely proportional to their frequency.\n",
    "\n",
    "3. Regularization\n",
    "We’ll apply L1 or L2 regularization to models like Logistic Regression, SVM, or any other linear models used in your ensemble.\n",
    "\n",
    "4.  Hyperparameter Tuning\n",
    "We'll use grid search to find the best hyperparameters for the models.\n",
    "\n",
    "5. Cross-Validation\n",
    "We'll use cross-validation to validate the models' performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Load the train data\n",
    "train_path = r\"../data/clean/test.parquet\"\n",
    "data_train = pd.read_parquet(train_path)\n",
    "\n",
    "# test data\n",
    "test_path = r\"../data/clean/test.parquet\"\n",
    "data_test = pd.read_parquet(test_path)\n",
    "\n",
    "# stack the data\n",
    "data = pd.concat([data_train, data_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "y = data.pop('Y')\n",
    "X = data\n",
    "# Handle imbalanced data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep on improving our data pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "Accuracy: 0.5833333333333334\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.33      0.44         6\n",
      "         1.0       0.56      0.83      0.67         6\n",
      "\n",
      "    accuracy                           0.58        12\n",
      "   macro avg       0.61      0.58      0.56        12\n",
      "weighted avg       0.61      0.58      0.56        12\n",
      "\n",
      "============================================================\n",
      "Model: RandomForest\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "============================================================\n",
      "Model: SVM\n",
      "Accuracy: 0.9166666666666666\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      1.00      0.92         6\n",
      "         1.0       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.93      0.92      0.92        12\n",
      "weighted avg       0.93      0.92      0.92        12\n",
      "\n",
      "============================================================\n",
      "Model: GradientBoosting\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "============================================================\n",
      "Model: XGBoost\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         6\n",
      "         1.0       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        12\n",
      "   macro avg       1.00      1.00      1.00        12\n",
      "weighted avg       1.00      1.00      1.00        12\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Define the models with pipelines\n",
    "pipelines = {\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ]),\n",
    "    'RandomForest': Pipeline([\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "    'SVM': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', SVC(random_state=42))\n",
    "    ]),\n",
    "    'GradientBoosting': Pipeline([\n",
    "        ('clf', GradientBoostingClassifier(random_state=42))\n",
    "    ]),\n",
    "    'XGBoost': Pipeline([\n",
    "        ('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    results[name] = (accuracy, report)\n",
    "\n",
    "# Print results\n",
    "for model_name, (accuracy, report) in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCH2VY_RrTJk",
    "outputId": "684e569e-4495-41d2-d628-27b92bcc3a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "Accuracy: 0.6071428571428571\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.36      0.48        14\n",
      "           1       0.57      0.86      0.69        14\n",
      "\n",
      "    accuracy                           0.61        28\n",
      "   macro avg       0.64      0.61      0.58        28\n",
      "weighted avg       0.64      0.61      0.58        28\n",
      "\n",
      "============================================================\n",
      "Model: RandomForest\n",
      "Accuracy: 0.7142857142857143\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69        14\n",
      "           1       0.69      0.79      0.73        14\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.72      0.71      0.71        28\n",
      "weighted avg       0.72      0.71      0.71        28\n",
      "\n",
      "============================================================\n",
      "Model: SVM\n",
      "Accuracy: 0.6428571428571429\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.50      0.58        14\n",
      "           1       0.61      0.79      0.69        14\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.66      0.64      0.64        28\n",
      "weighted avg       0.66      0.64      0.64        28\n",
      "\n",
      "============================================================\n",
      "Model: GradientBoosting\n",
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.70        14\n",
      "           1       0.68      0.93      0.79        14\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.79      0.75      0.74        28\n",
      "weighted avg       0.79      0.75      0.74        28\n",
      "\n",
      "============================================================\n",
      "Model: XGBoost\n",
      "Accuracy: 0.7142857142857143\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.57      0.67        14\n",
      "           1       0.67      0.86      0.75        14\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.73      0.71      0.71        28\n",
      "weighted avg       0.73      0.71      0.71        28\n",
      "\n",
      "============================================================\n",
      "Tuning hyperparameters for LogisticRegression...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 6 is smaller than n_iter=20. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................clf__C=0.1, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................clf__C=0.1, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................clf__C=0.1, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................clf__C=0.1, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END ........................clf__C=1, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........................clf__C=1, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................clf__C=0.1, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.1, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........................clf__C=1, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END ........................clf__C=1, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................clf__C=10, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END ...................clf__C=10, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END ...................clf__C=10, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END ...................clf__C=10, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END ...................clf__C=10, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END .......................clf__C=10, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......................clf__C=10, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......................clf__C=10, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................clf__C=1, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END .......................clf__C=10, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END .......................clf__C=10, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.1, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.1, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.1, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END ......................clf__C=0.1, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................clf__C=1, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END ....................clf__C=1, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END ....................clf__C=1, clf__solver=liblinear; total time=   0.0s\n",
      "[CV] END ........................clf__C=1, clf__solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................clf__C=1, clf__solver=liblinear; total time=   0.0s\n",
      "Tuning hyperparameters for RandomForest...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=1, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=1, clf__min_samples_split=5, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.4s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=2, clf__min_samples_split=5, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=2, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=None, clf__min_samples_leaf=4, clf__min_samples_split=2, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.4s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.4s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.4s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.4s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=200; total time=   0.4s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=4, clf__min_samples_split=5, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=20, clf__min_samples_leaf=1, clf__min_samples_split=2, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_leaf=4, clf__min_samples_split=10, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__max_depth=10, clf__min_samples_leaf=2, clf__min_samples_split=10, clf__n_estimators=50; total time=   0.1s\n",
      "Tuning hyperparameters for SVM...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END .....................clf__C=0.1, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .....................clf__C=0.1, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .....................clf__C=0.1, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .....................clf__C=0.1, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .....................clf__C=0.1, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................clf__C=0.1, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................clf__C=1, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .......................clf__C=1, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .......................clf__C=1, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .......................clf__C=1, clf__kernel=linear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 6 is smaller than n_iter=20. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................clf__C=1, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ..........................clf__C=1, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................clf__C=10, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ......................clf__C=10, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ......................clf__C=10, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END ......................clf__C=10, clf__kernel=linear; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__kernel=rbf; total time=   0.0s[CV] END ......................clf__C=10, clf__kernel=linear; total time=   0.0s\n",
      "\n",
      "[CV] END .........................clf__C=10, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__kernel=rbf; total time=   0.0s\n",
      "[CV] END .........................clf__C=10, clf__kernel=rbf; total time=   0.0s\n",
      "Tuning hyperparameters for GradientBoosting...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.4s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.4s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=200; total time=   0.8s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=200; total time=   0.8s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=200; total time=   0.9s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=200; total time=   1.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=200; total time=   1.2s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100; total time=   0.7s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100; total time=   0.7s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100; total time=   0.8s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100; total time=   0.8s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100; total time=   0.8s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=100; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=50; total time=   0.4s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=100; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=200; total time=   1.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=100; total time=   0.4s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=200; total time=   1.2s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=100; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=100; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=100; total time=   0.4s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=200; total time=   1.4s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=100; total time=   0.4s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=200; total time=   1.3s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=200; total time=   1.4s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=200; total time=   0.8s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=200; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=50; total time=   0.3s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=200; total time=   0.9s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.4s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=200; total time=   1.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.4s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.4s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.4s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=200; total time=   1.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=200; total time=   1.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.5s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.2s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=100; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=100; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=100; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=100; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=100; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=200; total time=   0.6s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=200; total time=   0.7s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=200; total time=   0.7s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=200; total time=   0.7s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=200; total time=   0.7s\n",
      "Tuning hyperparameters for XGBoost...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=7, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=3, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100; total time=   0.1s\n",
      "\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=50; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.1, clf__max_depth=7, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.01, clf__max_depth=3, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=100; total time=   0.1s\n",
      "\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=7, clf__n_estimators=100; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=3, clf__n_estimators=50; total time=   0.0s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=200; total time=   0.1s\n",
      "[CV] END clf__learning_rate=0.2, clf__max_depth=5, clf__n_estimators=200; total time=   0.0s\n",
      "Best LogisticRegression Model\n",
      "Accuracy: 0.6071428571428571\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.36      0.48        14\n",
      "           1       0.57      0.86      0.69        14\n",
      "\n",
      "    accuracy                           0.61        28\n",
      "   macro avg       0.64      0.61      0.58        28\n",
      "weighted avg       0.64      0.61      0.58        28\n",
      "\n",
      "Best Parameters: {'memory': None, 'steps': [('scaler', StandardScaler()), ('clf', LogisticRegression(C=1, max_iter=1000, random_state=42, solver='liblinear'))], 'verbose': False, 'scaler': StandardScaler(), 'clf': LogisticRegression(C=1, max_iter=1000, random_state=42, solver='liblinear'), 'scaler__copy': True, 'scaler__with_mean': True, 'scaler__with_std': True, 'clf__C': 1, 'clf__class_weight': None, 'clf__dual': False, 'clf__fit_intercept': True, 'clf__intercept_scaling': 1, 'clf__l1_ratio': None, 'clf__max_iter': 1000, 'clf__multi_class': 'deprecated', 'clf__n_jobs': None, 'clf__penalty': 'l2', 'clf__random_state': 42, 'clf__solver': 'liblinear', 'clf__tol': 0.0001, 'clf__verbose': 0, 'clf__warm_start': False}\n",
      "============================================================\n",
      "Best RandomForest Model\n",
      "Accuracy: 0.8214285714285714\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80        14\n",
      "           1       0.76      0.93      0.84        14\n",
      "\n",
      "    accuracy                           0.82        28\n",
      "   macro avg       0.84      0.82      0.82        28\n",
      "weighted avg       0.84      0.82      0.82        28\n",
      "\n",
      "Best Parameters: {'memory': None, 'steps': [('clf', RandomForestClassifier(min_samples_leaf=2, random_state=42))], 'verbose': False, 'clf': RandomForestClassifier(min_samples_leaf=2, random_state=42), 'clf__bootstrap': True, 'clf__ccp_alpha': 0.0, 'clf__class_weight': None, 'clf__criterion': 'gini', 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__max_leaf_nodes': None, 'clf__max_samples': None, 'clf__min_impurity_decrease': 0.0, 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 2, 'clf__min_weight_fraction_leaf': 0.0, 'clf__monotonic_cst': None, 'clf__n_estimators': 100, 'clf__n_jobs': None, 'clf__oob_score': False, 'clf__random_state': 42, 'clf__verbose': 0, 'clf__warm_start': False}\n",
      "============================================================\n",
      "Best SVM Model\n",
      "Accuracy: 0.6071428571428571\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.36      0.48        14\n",
      "           1       0.57      0.86      0.69        14\n",
      "\n",
      "    accuracy                           0.61        28\n",
      "   macro avg       0.64      0.61      0.58        28\n",
      "weighted avg       0.64      0.61      0.58        28\n",
      "\n",
      "Best Parameters: {'memory': None, 'steps': [('scaler', StandardScaler()), ('clf', SVC(C=1, kernel='linear', random_state=42))], 'verbose': False, 'scaler': StandardScaler(), 'clf': SVC(C=1, kernel='linear', random_state=42), 'scaler__copy': True, 'scaler__with_mean': True, 'scaler__with_std': True, 'clf__C': 1, 'clf__break_ties': False, 'clf__cache_size': 200, 'clf__class_weight': None, 'clf__coef0': 0.0, 'clf__decision_function_shape': 'ovr', 'clf__degree': 3, 'clf__gamma': 'scale', 'clf__kernel': 'linear', 'clf__max_iter': -1, 'clf__probability': False, 'clf__random_state': 42, 'clf__shrinking': True, 'clf__tol': 0.001, 'clf__verbose': False}\n",
      "============================================================\n",
      "Best GradientBoosting Model\n",
      "Accuracy: 0.6785714285714286\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.57      0.64        14\n",
      "           1       0.65      0.79      0.71        14\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.69      0.68      0.67        28\n",
      "weighted avg       0.69      0.68      0.67        28\n",
      "\n",
      "Best Parameters: {'memory': None, 'steps': [('clf', GradientBoostingClassifier(learning_rate=0.01, n_estimators=50, random_state=42))], 'verbose': False, 'clf': GradientBoostingClassifier(learning_rate=0.01, n_estimators=50, random_state=42), 'clf__ccp_alpha': 0.0, 'clf__criterion': 'friedman_mse', 'clf__init': None, 'clf__learning_rate': 0.01, 'clf__loss': 'log_loss', 'clf__max_depth': 3, 'clf__max_features': None, 'clf__max_leaf_nodes': None, 'clf__min_impurity_decrease': 0.0, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__min_weight_fraction_leaf': 0.0, 'clf__n_estimators': 50, 'clf__n_iter_no_change': None, 'clf__random_state': 42, 'clf__subsample': 1.0, 'clf__tol': 0.0001, 'clf__validation_fraction': 0.1, 'clf__verbose': 0, 'clf__warm_start': False}\n",
      "============================================================\n",
      "Best XGBoost Model\n",
      "Accuracy: 0.7142857142857143\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.57      0.67        14\n",
      "           1       0.67      0.86      0.75        14\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.73      0.71      0.71        28\n",
      "weighted avg       0.73      0.71      0.71        28\n",
      "\n",
      "Best Parameters: {'memory': None, 'steps': [('clf', XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='logloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=42, ...))], 'verbose': False, 'clf': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='logloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=42, ...), 'clf__objective': 'binary:logistic', 'clf__base_score': None, 'clf__booster': None, 'clf__callbacks': None, 'clf__colsample_bylevel': None, 'clf__colsample_bynode': None, 'clf__colsample_bytree': None, 'clf__device': None, 'clf__early_stopping_rounds': None, 'clf__enable_categorical': False, 'clf__eval_metric': 'logloss', 'clf__feature_types': None, 'clf__gamma': None, 'clf__grow_policy': None, 'clf__importance_type': None, 'clf__interaction_constraints': None, 'clf__learning_rate': 0.01, 'clf__max_bin': None, 'clf__max_cat_threshold': None, 'clf__max_cat_to_onehot': None, 'clf__max_delta_step': None, 'clf__max_depth': 3, 'clf__max_leaves': None, 'clf__min_child_weight': None, 'clf__missing': nan, 'clf__monotone_constraints': None, 'clf__multi_strategy': None, 'clf__n_estimators': 200, 'clf__n_jobs': None, 'clf__num_parallel_tree': None, 'clf__random_state': 42, 'clf__reg_alpha': None, 'clf__reg_lambda': None, 'clf__sampling_method': None, 'clf__scale_pos_weight': None, 'clf__subsample': None, 'clf__tree_method': None, 'clf__validate_parameters': None, 'clf__verbosity': None, 'clf__use_label_encoder': False}\n",
      "============================================================\n",
      "Cross-Validation Accuracy for LogisticRegression: 0.6013227513227513 ± 0.045734306315570794\n",
      "Cross-Validation Accuracy for RandomForest: 0.674074074074074 ± 0.06744008411167902\n",
      "Cross-Validation Accuracy for SVM: 0.6084656084656085 ± 0.04367083073867509\n",
      "Cross-Validation Accuracy for GradientBoosting: 0.587037037037037 ± 0.05272719725551399\n",
      "Cross-Validation Accuracy for XGBoost: 0.6161375661375661 ± 0.01101622371092967\n",
      "Voting Classifier Model\n",
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.64      0.72        14\n",
      "           1       0.71      0.86      0.77        14\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.76      0.75      0.75        28\n",
      "weighted avg       0.76      0.75      0.75        28\n",
      "\n",
      "Cross-Validation Accuracy for Voting Classifier: 0.6232804232804232 ± 0.034890559439281855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_voting_classifier_{date_time}.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter Tuning using RandomizedSearchCV\n",
    "tuning_params = {\n",
    "    'RandomForest': {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__max_depth': [None, 10, 20, 30],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'clf__max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'clf__n_estimators': [50, 100, 200],\n",
    "        'clf__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'clf__max_depth': [3, 5, 7]\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    print(f\"Tuning hyperparameters for {name}...\")\n",
    "    random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=tuning_params[name], n_iter=20, cv=5, n_jobs=-1, verbose=2, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    best_models[name] = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the best models\n",
    "for name, best_model in best_models.items():\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(f\"Best {name} Model\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"Best Parameters:\", best_model.get_params())\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Cross-Validation for the best models\n",
    "for name, best_model in best_models.items():\n",
    "    cv_scores = cross_val_score(best_model, X_res, y_res, cv=StratifiedKFold(5))\n",
    "    print(f\"Cross-Validation Accuracy for {name}: {cv_scores.mean()} ± {cv_scores.std()}\")\n",
    "\n",
    "# Ensemble Model - Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', best_models['LogisticRegression']),\n",
    "    ('rf', best_models['RandomForest']),\n",
    "    ('svm', best_models['SVM']),\n",
    "    ('gb', best_models['GradientBoosting']),\n",
    "    ('xgb', best_models['XGBoost'])\n",
    "], voting='hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Voting Classifier Model\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Cross-Validation for Voting Classifier\n",
    "cv_scores = cross_val_score(voting_clf, X_res, y_res, cv=StratifiedKFold(5))\n",
    "print(f\"Cross-Validation Accuracy for Voting Classifier: {cv_scores.mean()} ± {cv_scores.std()}\")\n",
    "\n",
    "# Save the best models and voting classifier\n",
    "date_time = pd.Timestamp.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "for name, best_model in best_models.items():\n",
    "    joblib.dump(best_model, f'best_{name}_model.pkl')\n",
    "joblib.dump(voting_clf, 'best_voting_classifier_{date_time}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sz3-rRa4sebE",
    "outputId": "5a1b41dd-5695-450c-8482-934c9bcd0c97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 23:20:16,985] A new study created in memory with name: no-name-3cad9318-4c96-4c43-9e9d-8adf78ff67c5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "Accuracy: 0.6071428571428571\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.36      0.48        14\n",
      "           1       0.57      0.86      0.69        14\n",
      "\n",
      "    accuracy                           0.61        28\n",
      "   macro avg       0.64      0.61      0.58        28\n",
      "weighted avg       0.64      0.61      0.58        28\n",
      "\n",
      "============================================================\n",
      "Model: RandomForest\n",
      "Accuracy: 0.7142857142857143\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69        14\n",
      "           1       0.69      0.79      0.73        14\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.72      0.71      0.71        28\n",
      "weighted avg       0.72      0.71      0.71        28\n",
      "\n",
      "============================================================\n",
      "Model: SVM\n",
      "Accuracy: 0.6428571428571429\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.50      0.58        14\n",
      "           1       0.61      0.79      0.69        14\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.66      0.64      0.64        28\n",
      "weighted avg       0.66      0.64      0.64        28\n",
      "\n",
      "============================================================\n",
      "Model: GradientBoosting\n",
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.70        14\n",
      "           1       0.68      0.93      0.79        14\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.79      0.75      0.74        28\n",
      "weighted avg       0.79      0.75      0.74        28\n",
      "\n",
      "============================================================\n",
      "Model: XGBoost\n",
      "Accuracy: 0.7142857142857143\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.57      0.67        14\n",
      "           1       0.67      0.86      0.75        14\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.73      0.71      0.71        28\n",
      "weighted avg       0.73      0.71      0.71        28\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 23:20:17,585] Trial 0 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 74, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.5818181818181818.\n",
      "[I 2024-08-08 23:20:18,894] Trial 1 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 177, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.5818181818181818.\n",
      "[I 2024-08-08 23:20:19,538] Trial 2 finished with value: 0.5272727272727272 and parameters: {'n_estimators': 98, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.5818181818181818.\n",
      "[I 2024-08-08 23:20:20,105] Trial 3 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 86, 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:21,352] Trial 4 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 132, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:21,906] Trial 5 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 68, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:23,380] Trial 6 finished with value: 0.5909090909090909 and parameters: {'n_estimators': 197, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:24,708] Trial 7 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 190, 'max_depth': 21, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:25,813] Trial 8 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 137, 'max_depth': 27, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:27,025] Trial 9 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 179, 'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:27,424] Trial 10 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 51, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:28,434] Trial 11 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 135, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:29,169] Trial 12 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 109, 'max_depth': 23, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:30,111] Trial 13 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 147, 'max_depth': 25, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:30,838] Trial 14 finished with value: 0.5909090909090909 and parameters: {'n_estimators': 102, 'max_depth': 29, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:31,946] Trial 15 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 157, 'max_depth': 22, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:32,765] Trial 16 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 117, 'max_depth': 25, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:33,467] Trial 17 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 93, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:34,079] Trial 18 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 81, 'max_depth': 24, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:35,245] Trial 19 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 156, 'max_depth': 27, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:36,284] Trial 20 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 122, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:37,594] Trial 21 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 159, 'max_depth': 21, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:38,589] Trial 22 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 141, 'max_depth': 23, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.5999999999999999.\n",
      "[I 2024-08-08 23:20:39,764] Trial 23 finished with value: 0.609090909090909 and parameters: {'n_estimators': 164, 'max_depth': 27, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:40,937] Trial 24 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 177, 'max_depth': 27, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:42,056] Trial 25 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 167, 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:42,473] Trial 26 finished with value: 0.5454545454545454 and parameters: {'n_estimators': 51, 'max_depth': 26, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:43,556] Trial 27 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 146, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:44,359] Trial 28 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 116, 'max_depth': 28, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:45,035] Trial 29 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 84, 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:46,222] Trial 30 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 129, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:47,502] Trial 31 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 159, 'max_depth': 22, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:48,802] Trial 32 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 169, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:49,757] Trial 33 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 140, 'max_depth': 25, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:50,779] Trial 34 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 151, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:51,884] Trial 35 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 168, 'max_depth': 23, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:53,204] Trial 36 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 181, 'max_depth': 26, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:53,689] Trial 37 finished with value: 0.5545454545454545 and parameters: {'n_estimators': 61, 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:55,059] Trial 38 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 199, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:56,456] Trial 39 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 186, 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:57,608] Trial 40 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 135, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:58,769] Trial 41 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 169, 'max_depth': 22, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:20:59,825] Trial 42 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 165, 'max_depth': 23, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:21:00,822] Trial 43 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 149, 'max_depth': 24, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:21:02,117] Trial 44 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 176, 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:21:03,637] Trial 45 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 188, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:21:04,705] Trial 46 finished with value: 0.6 and parameters: {'n_estimators': 157, 'max_depth': 24, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:21:05,947] Trial 47 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 155, 'max_depth': 26, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:21:06,834] Trial 48 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 128, 'max_depth': 28, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 23 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:21:07,998] Trial 49 finished with value: 0.6 and parameters: {'n_estimators': 141, 'max_depth': 24, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 23 with value: 0.609090909090909.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Model with Optuna\n",
      "Accuracy: 0.7857142857142857\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.64      0.75        14\n",
      "           1       0.72      0.93      0.81        14\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.81      0.79      0.78        28\n",
      "weighted avg       0.81      0.79      0.78        28\n",
      "\n",
      "Voting Classifier Model\n",
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.57      0.70        14\n",
      "           1       0.68      0.93      0.79        14\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.79      0.75      0.74        28\n",
      "weighted avg       0.79      0.75      0.74        28\n",
      "\n",
      "Cross-Validation Accuracy for Voting Classifier: 0.644973544973545 ± 0.05264882603638943\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['best_voting_classifier_{date_time}.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tuning using Optuna for an example model (Random Forest)\n",
    "def objective(trial):\n",
    "    param_grid = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 30),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n",
    "    }\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', RandomForestClassifier(random_state=42, **param_grid))\n",
    "    ])\n",
    "\n",
    "    score = cross_val_score(pipeline, X_train, y_train, cv=StratifiedKFold(5)).mean()\n",
    "    return score\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "best_params = study.best_params\n",
    "\n",
    "# Train and evaluate the best RandomForest model with optimized hyperparameters\n",
    "best_rf_pipeline = Pipeline([\n",
    "    ('clf', RandomForestClassifier(random_state=42, **best_params))\n",
    "])\n",
    "best_rf_pipeline.fit(X_train, y_train)\n",
    "y_pred = best_rf_pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Best RandomForest Model with Optuna\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Evaluate the ensemble model (Voting Classifier)\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', pipelines['LogisticRegression']),\n",
    "    ('rf', pipelines['RandomForest']),\n",
    "    ('svm', pipelines['SVM']),\n",
    "    ('gb', pipelines['GradientBoosting']),\n",
    "    ('xgb', pipelines['XGBoost'])\n",
    "], voting='hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Voting Classifier Model\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Cross-Validation for Voting Classifier\n",
    "cv_scores = cross_val_score(voting_clf, X_res, y_res, cv=StratifiedKFold(5))\n",
    "print(f\"Cross-Validation Accuracy for Voting Classifier: {cv_scores.mean()} ± {cv_scores.std()}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Save the best models and voting classifier\n",
    "date_time = pd.Timestamp.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "for name, best_model in best_models.items():\n",
    "    joblib.dump(best_model, f'best_{name}_model.pkl')\n",
    "joblib.dump(voting_clf, f'best_voting_classifier_{date_time}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0cfEMTpxFln"
   },
   "source": [
    "## Implementation of Stacking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackingClassifier\n",
    "+ polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "A0LzoF9syZkF",
    "outputId": "dd1fcf6d-0343-4159-c6a3-aac4e1e30ba2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Model\n",
      "Accuracy: 0.6785714285714286\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.57      0.64        14\n",
      "           1       0.65      0.79      0.71        14\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.69      0.68      0.67        28\n",
      "weighted avg       0.69      0.68      0.67        28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy for Stacking Classifier: 0.6013227513227513 ± 0.06458278303121939\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['stacking_classifier.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the base models with pipelines\n",
    "base_models = [\n",
    "    ('lr', Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=1000, random_state=42))])),\n",
    "    ('rf', Pipeline([('clf', RandomForestClassifier(random_state=42))])),\n",
    "    ('svm', Pipeline([('scaler', StandardScaler()), ('clf', SVC(random_state=42))])),\n",
    "    ('gb', Pipeline([('clf', GradientBoostingClassifier(random_state=42))])),\n",
    "    ('xgb', Pipeline([('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))])),\n",
    "    ('mlp', Pipeline([('scaler', StandardScaler()), ('clf', MLPClassifier(random_state=42, max_iter=500))]))\n",
    "]\n",
    "\n",
    "# Define the meta-model with polynomial features\n",
    "meta_model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Stacking Classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Train and evaluate the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Stacking Classifier Model\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Cross-Validation for Stacking Classifier\n",
    "cv_scores = cross_val_score(stacking_clf, X_res, y_res, cv=StratifiedKFold(5))\n",
    "print(f\"Cross-Validation Accuracy for Stacking Classifier: {cv_scores.mean()} ± {cv_scores.std()}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Save the stacking classifier\n",
    "joblib.dump(stacking_clf, f'../models/stacking_classifier_{date_time}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking 3\n",
    "* Polynomial features\n",
    "+ Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-08 23:38:42,382] A new study created in memory with name: no-name-80172b57-e1f9-4279-b1a7-d04e592d3ea1\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:42,453] Trial 0 finished with value: 0.5636363636363636 and parameters: {'C': 0.0007554940789471911, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5636363636363636.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:42,523] Trial 1 finished with value: 0.5636363636363636 and parameters: {'C': 3.336210937773773e-05, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5636363636363636.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:42,604] Trial 2 finished with value: 0.5636363636363636 and parameters: {'C': 4.629632888757718, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5636363636363636.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:42,689] Trial 3 finished with value: 0.5636363636363636 and parameters: {'C': 0.021354801731519654, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5636363636363636.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:42,765] Trial 4 finished with value: 0.5636363636363636 and parameters: {'C': 0.0006919227570777776, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5636363636363636.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:42,833] Trial 5 finished with value: 0.5636363636363636 and parameters: {'C': 0.5165735136253168, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5636363636363636.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:42,884] Trial 6 finished with value: 0.5545454545454545 and parameters: {'C': 0.38721945885427905, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5636363636363636.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:42,940] Trial 7 finished with value: 0.5636363636363636 and parameters: {'C': 0.0002005243319711552, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5636363636363636.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:42,997] Trial 8 finished with value: 0.5636363636363636 and parameters: {'C': 0.00014555744420530046, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5636363636363636.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:43,062] Trial 9 finished with value: 0.5636363636363636 and parameters: {'C': 0.00010619780944907052, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5636363636363636.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:43,131] Trial 10 finished with value: 0.5727272727272726 and parameters: {'C': 0.006932508231847436, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:43,202] Trial 11 finished with value: 0.5727272727272726 and parameters: {'C': 0.005680405812845983, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:43,264] Trial 12 finished with value: 0.5727272727272726 and parameters: {'C': 0.010210574527692673, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:43,326] Trial 13 finished with value: 0.5636363636363636 and parameters: {'C': 84.83739376151318, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:43,421] Trial 14 finished with value: 0.5727272727272726 and parameters: {'C': 0.006590345910344024, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:43,494] Trial 15 finished with value: 0.5454545454545454 and parameters: {'C': 0.17066426125133913, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:43,575] Trial 16 finished with value: 0.5636363636363636 and parameters: {'C': 0.0022611756494542775, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:43,665] Trial 17 finished with value: 0.5545454545454545 and parameters: {'C': 0.07877597943643377, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:43,759] Trial 18 finished with value: 0.5636363636363636 and parameters: {'C': 1.383314393088665e-05, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:43,834] Trial 19 finished with value: 0.5636363636363636 and parameters: {'C': 3.792099151365807, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:43,905] Trial 20 finished with value: 0.5636363636363636 and parameters: {'C': 0.00231183178294609, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:43,969] Trial 21 finished with value: 0.5636363636363636 and parameters: {'C': 0.016940248869898915, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,023] Trial 22 finished with value: 0.5727272727272726 and parameters: {'C': 0.005160764875550472, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,081] Trial 23 finished with value: 0.5727272727272726 and parameters: {'C': 0.05100859625499787, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,143] Trial 24 finished with value: 0.5727272727272726 and parameters: {'C': 0.008738465049156912, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,208] Trial 25 finished with value: 0.5636363636363636 and parameters: {'C': 0.001737579807116154, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,270] Trial 26 finished with value: 0.5636363636363636 and parameters: {'C': 0.0006094356867091058, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,331] Trial 27 finished with value: 0.5636363636363636 and parameters: {'C': 1.1099925935914738, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,390] Trial 28 finished with value: 0.5818181818181818 and parameters: {'C': 0.03840306793793413, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,458] Trial 29 finished with value: 0.5545454545454545 and parameters: {'C': 0.08553492545794776, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,515] Trial 30 finished with value: 0.5818181818181818 and parameters: {'C': 0.035179809216767284, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,580] Trial 31 finished with value: 0.5818181818181818 and parameters: {'C': 0.030153218502393695, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,646] Trial 32 finished with value: 0.5818181818181818 and parameters: {'C': 0.036096203662155935, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,716] Trial 33 finished with value: 0.5454545454545454 and parameters: {'C': 0.18583770668566146, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,788] Trial 34 finished with value: 0.5818181818181818 and parameters: {'C': 0.03446136953105178, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,863] Trial 35 finished with value: 0.5636363636363636 and parameters: {'C': 1.5559757207203477, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:44,941] Trial 36 finished with value: 0.5727272727272726 and parameters: {'C': 0.024584813843866626, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:45,016] Trial 37 finished with value: 0.5454545454545454 and parameters: {'C': 0.1859064321401747, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:45,091] Trial 38 finished with value: 0.5636363636363636 and parameters: {'C': 22.690160921338958, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:45,154] Trial 39 finished with value: 0.5545454545454545 and parameters: {'C': 0.3869370496726698, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:45,227] Trial 40 finished with value: 0.5545454545454545 and parameters: {'C': 0.08848487801812073, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:45,286] Trial 41 finished with value: 0.5818181818181818 and parameters: {'C': 0.033695926539523455, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:45,345] Trial 42 finished with value: 0.5818181818181818 and parameters: {'C': 0.0345707751618727, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:45,400] Trial 43 finished with value: 0.5636363636363636 and parameters: {'C': 0.01599606883919441, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:45,465] Trial 44 finished with value: 0.5636363636363636 and parameters: {'C': 0.5881759894508245, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:45,527] Trial 45 finished with value: 0.5727272727272726 and parameters: {'C': 0.05401577899329652, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:45,587] Trial 46 finished with value: 0.5727272727272726 and parameters: {'C': 0.003402517589125165, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:45,663] Trial 47 finished with value: 0.5454545454545454 and parameters: {'C': 0.13876307804077945, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:45,738] Trial 48 finished with value: 0.5636363636363636 and parameters: {'C': 0.0011183605514544692, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
      "[I 2024-08-08 23:38:45,794] Trial 49 finished with value: 0.5636363636363636 and parameters: {'C': 0.0137548188127308, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 28 with value: 0.5818181818181818.\n",
      "[I 2024-08-08 23:38:45,795] A new study created in memory with name: no-name-9ba0584b-e8c1-4255-a9da-6e6482414699\n",
      "[I 2024-08-08 23:38:46,800] Trial 0 finished with value: 0.5909090909090909 and parameters: {'n_estimators': 141, 'max_depth': 21, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.5909090909090909.\n",
      "[I 2024-08-08 23:38:47,694] Trial 1 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 143, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.5909090909090909.\n",
      "[I 2024-08-08 23:38:48,741] Trial 2 finished with value: 0.6 and parameters: {'n_estimators': 160, 'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.6.\n",
      "[I 2024-08-08 23:38:49,324] Trial 3 finished with value: 0.609090909090909 and parameters: {'n_estimators': 88, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:38:50,572] Trial 4 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 196, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:38:51,586] Trial 5 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 145, 'max_depth': 28, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:38:52,654] Trial 6 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 161, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:38:53,499] Trial 7 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 137, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:38:54,517] Trial 8 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 153, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:38:55,399] Trial 9 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 153, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:38:55,924] Trial 10 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 70, 'max_depth': 25, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:38:56,572] Trial 11 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 89, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:38:57,282] Trial 12 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 104, 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:38:57,629] Trial 13 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 51, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:38:58,486] Trial 14 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 114, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:38:59,657] Trial 15 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 189, 'max_depth': 27, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:00,255] Trial 16 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 89, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:01,360] Trial 17 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 169, 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:02,189] Trial 18 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 124, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:03,250] Trial 19 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 177, 'max_depth': 23, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:03,852] Trial 20 finished with value: 0.5909090909090909 and parameters: {'n_estimators': 96, 'max_depth': 28, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:04,604] Trial 21 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 123, 'max_depth': 21, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:05,101] Trial 22 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 74, 'max_depth': 26, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:05,910] Trial 23 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 131, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:06,700] Trial 24 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 109, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:07,469] Trial 25 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 131, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:07,931] Trial 26 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 72, 'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:09,236] Trial 27 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 172, 'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:10,038] Trial 28 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 120, 'max_depth': 23, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:10,843] Trial 29 finished with value: 0.5909090909090909 and parameters: {'n_estimators': 135, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:12,038] Trial 30 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 186, 'max_depth': 28, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:12,736] Trial 31 finished with value: 0.5909090909090909 and parameters: {'n_estimators': 102, 'max_depth': 17, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:13,410] Trial 32 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 111, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:14,046] Trial 33 finished with value: 0.6 and parameters: {'n_estimators': 93, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:14,652] Trial 34 finished with value: 0.6 and parameters: {'n_estimators': 85, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:15,327] Trial 35 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 82, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:15,827] Trial 36 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 64, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:16,297] Trial 37 finished with value: 0.5363636363636364 and parameters: {'n_estimators': 60, 'max_depth': 19, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:16,886] Trial 38 finished with value: 0.618181818181818 and parameters: {'n_estimators': 81, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.618181818181818.\n",
      "[I 2024-08-08 23:39:17,463] Trial 39 finished with value: 0.609090909090909 and parameters: {'n_estimators': 78, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.618181818181818.\n",
      "[I 2024-08-08 23:39:17,997] Trial 40 finished with value: 0.609090909090909 and parameters: {'n_estimators': 80, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.618181818181818.\n",
      "[I 2024-08-08 23:39:18,663] Trial 41 finished with value: 0.609090909090909 and parameters: {'n_estimators': 78, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.618181818181818.\n",
      "[I 2024-08-08 23:39:19,159] Trial 42 finished with value: 0.618181818181818 and parameters: {'n_estimators': 77, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.618181818181818.\n",
      "[I 2024-08-08 23:39:19,587] Trial 43 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 64, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.618181818181818.\n",
      "[I 2024-08-08 23:39:19,991] Trial 44 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 60, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.618181818181818.\n",
      "[I 2024-08-08 23:39:20,626] Trial 45 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 99, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.618181818181818.\n",
      "[I 2024-08-08 23:39:20,990] Trial 46 finished with value: 0.5272727272727272 and parameters: {'n_estimators': 52, 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 38 with value: 0.618181818181818.\n",
      "[I 2024-08-08 23:39:21,576] Trial 47 finished with value: 0.609090909090909 and parameters: {'n_estimators': 82, 'max_depth': 22, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.618181818181818.\n",
      "[I 2024-08-08 23:39:22,062] Trial 48 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 69, 'max_depth': 23, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.618181818181818.\n",
      "[I 2024-08-08 23:39:22,692] Trial 49 finished with value: 0.609090909090909 and parameters: {'n_estimators': 90, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 38 with value: 0.618181818181818.\n",
      "[I 2024-08-08 23:39:22,694] A new study created in memory with name: no-name-6daec1ec-4586-4ea9-ad98-596d1438b451\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:22,752] Trial 0 finished with value: 0.5636363636363636 and parameters: {'C': 0.004051740373778313, 'kernel': 'rbf'}. Best is trial 0 with value: 0.5636363636363636.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:22,808] Trial 1 finished with value: 0.5636363636363636 and parameters: {'C': 0.0011184985744469775, 'kernel': 'rbf'}. Best is trial 0 with value: 0.5636363636363636.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:22,862] Trial 2 finished with value: 0.5 and parameters: {'C': 93.23165458012602, 'kernel': 'rbf'}. Best is trial 0 with value: 0.5636363636363636.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:22,926] Trial 3 finished with value: 0.5727272727272726 and parameters: {'C': 6.3063572670529915, 'kernel': 'linear'}. Best is trial 3 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,013] Trial 4 finished with value: 0.5727272727272726 and parameters: {'C': 71.11478948973577, 'kernel': 'linear'}. Best is trial 3 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,064] Trial 5 finished with value: 0.5818181818181818 and parameters: {'C': 0.5815162134164397, 'kernel': 'linear'}. Best is trial 5 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,118] Trial 6 finished with value: 0.5636363636363636 and parameters: {'C': 0.004783656868641194, 'kernel': 'rbf'}. Best is trial 5 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,201] Trial 7 finished with value: 0.5727272727272726 and parameters: {'C': 56.76553710000525, 'kernel': 'linear'}. Best is trial 5 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,274] Trial 8 finished with value: 0.5727272727272726 and parameters: {'C': 4.653438471179807, 'kernel': 'linear'}. Best is trial 5 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,379] Trial 9 finished with value: 0.5727272727272726 and parameters: {'C': 99.4182649838175, 'kernel': 'linear'}. Best is trial 5 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,438] Trial 10 finished with value: 0.5454545454545454 and parameters: {'C': 0.11333796093328029, 'kernel': 'linear'}. Best is trial 5 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,497] Trial 11 finished with value: 0.5818181818181818 and parameters: {'C': 0.9924175966949732, 'kernel': 'linear'}. Best is trial 5 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,558] Trial 12 finished with value: 0.5636363636363636 and parameters: {'C': 0.2517701415876267, 'kernel': 'linear'}. Best is trial 5 with value: 0.5818181818181818.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,630] Trial 13 finished with value: 0.5909090909090908 and parameters: {'C': 1.4828649591003096, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,697] Trial 14 finished with value: 0.5545454545454545 and parameters: {'C': 0.03965437072475004, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,774] Trial 15 finished with value: 0.5909090909090908 and parameters: {'C': 1.469185551294848, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,838] Trial 16 finished with value: 0.5727272727272726 and parameters: {'C': 5.523655249055512, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,906] Trial 17 finished with value: 0.5818181818181818 and parameters: {'C': 1.5228013396192248, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:23,957] Trial 18 finished with value: 0.509090909090909 and parameters: {'C': 15.800004339893949, 'kernel': 'rbf'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,014] Trial 19 finished with value: 0.5454545454545454 and parameters: {'C': 0.05490925537176103, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,076] Trial 20 finished with value: 0.5909090909090908 and parameters: {'C': 1.8036682362197258, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,139] Trial 21 finished with value: 0.5909090909090908 and parameters: {'C': 1.9828274498077103, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,241] Trial 22 finished with value: 0.5636363636363636 and parameters: {'C': 0.2566130234628934, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,345] Trial 23 finished with value: 0.5727272727272726 and parameters: {'C': 15.925906638827788, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,416] Trial 24 finished with value: 0.5727272727272726 and parameters: {'C': 2.4793707420072892, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,475] Trial 25 finished with value: 0.5727272727272726 and parameters: {'C': 0.4556603504849393, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,532] Trial 26 finished with value: 0.509090909090909 and parameters: {'C': 15.49257987734284, 'kernel': 'rbf'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,589] Trial 27 finished with value: 0.5818181818181818 and parameters: {'C': 0.7205613639895186, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,651] Trial 28 finished with value: 0.5545454545454545 and parameters: {'C': 0.13760217953969348, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,713] Trial 29 finished with value: 0.5636363636363636 and parameters: {'C': 0.02862351069626242, 'kernel': 'rbf'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,773] Trial 30 finished with value: 0.5727272727272726 and parameters: {'C': 2.922324196707304, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,837] Trial 31 finished with value: 0.5909090909090908 and parameters: {'C': 1.4090132591986118, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,921] Trial 32 finished with value: 0.5727272727272726 and parameters: {'C': 8.775624660651989, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:24,979] Trial 33 finished with value: 0.5727272727272726 and parameters: {'C': 2.5219448068983352, 'kernel': 'linear'}. Best is trial 13 with value: 0.5909090909090908.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,032] Trial 34 finished with value: 0.609090909090909 and parameters: {'C': 1.1866475347351457, 'kernel': 'rbf'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,088] Trial 35 finished with value: 0.5272727272727272 and parameters: {'C': 32.656105031406085, 'kernel': 'rbf'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,190] Trial 36 finished with value: 0.5545454545454545 and parameters: {'C': 0.8931719897648934, 'kernel': 'rbf'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,259] Trial 37 finished with value: 0.5818181818181818 and parameters: {'C': 0.40778157656375763, 'kernel': 'rbf'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,331] Trial 38 finished with value: 0.5818181818181818 and parameters: {'C': 4.04196813184183, 'kernel': 'rbf'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,395] Trial 39 finished with value: 0.5636363636363636 and parameters: {'C': 0.010218053590629194, 'kernel': 'rbf'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,464] Trial 40 finished with value: 0.5636363636363636 and parameters: {'C': 0.0015265740932776438, 'kernel': 'rbf'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,520] Trial 41 finished with value: 0.5909090909090908 and parameters: {'C': 1.4365370278903093, 'kernel': 'linear'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,591] Trial 42 finished with value: 0.5727272727272726 and parameters: {'C': 8.043324855403606, 'kernel': 'linear'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,655] Trial 43 finished with value: 0.5818181818181818 and parameters: {'C': 2.024919105166716, 'kernel': 'linear'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,716] Trial 44 finished with value: 0.5818181818181818 and parameters: {'C': 0.7037572498731485, 'kernel': 'linear'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,783] Trial 45 finished with value: 0.5545454545454545 and parameters: {'C': 0.14600633340607047, 'kernel': 'linear'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,840] Trial 46 finished with value: 0.5818181818181818 and parameters: {'C': 3.9342707456324053, 'kernel': 'rbf'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,900] Trial 47 finished with value: 0.5818181818181818 and parameters: {'C': 1.2657418968874952, 'kernel': 'linear'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:25,969] Trial 48 finished with value: 0.5727272727272726 and parameters: {'C': 0.35639180333598036, 'kernel': 'linear'}. Best is trial 34 with value: 0.609090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:41: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
      "[I 2024-08-08 23:39:26,041] Trial 49 finished with value: 0.5727272727272726 and parameters: {'C': 10.436197717247108, 'kernel': 'linear'}. Best is trial 34 with value: 0.609090909090909.\n",
      "[I 2024-08-08 23:39:26,043] A new study created in memory with name: no-name-63e7603a-f9ed-4aef-be9d-622bef34597b\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:27,088] Trial 0 finished with value: 0.4909090909090909 and parameters: {'n_estimators': 80, 'learning_rate': 0.014350443045382681, 'max_depth': 10}. Best is trial 0 with value: 0.4909090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:28,028] Trial 1 finished with value: 0.4909090909090909 and parameters: {'n_estimators': 84, 'learning_rate': 0.025641005291232342, 'max_depth': 8}. Best is trial 0 with value: 0.4909090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:29,640] Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 129, 'learning_rate': 0.022011798726745625, 'max_depth': 10}. Best is trial 2 with value: 0.5.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:30,576] Trial 3 finished with value: 0.4636363636363637 and parameters: {'n_estimators': 116, 'learning_rate': 0.020472908807217652, 'max_depth': 5}. Best is trial 2 with value: 0.5.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:31,861] Trial 4 finished with value: 0.4909090909090909 and parameters: {'n_estimators': 113, 'learning_rate': 0.044810052719439254, 'max_depth': 9}. Best is trial 2 with value: 0.5.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:33,998] Trial 5 finished with value: 0.4727272727272728 and parameters: {'n_estimators': 186, 'learning_rate': 0.01677442634259998, 'max_depth': 9}. Best is trial 2 with value: 0.5.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:34,558] Trial 6 finished with value: 0.5181818181818182 and parameters: {'n_estimators': 57, 'learning_rate': 0.010816189159347813, 'max_depth': 7}. Best is trial 6 with value: 0.5181818181818182.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:36,247] Trial 7 finished with value: 0.5 and parameters: {'n_estimators': 168, 'learning_rate': 0.00899544530056188, 'max_depth': 7}. Best is trial 6 with value: 0.5181818181818182.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:36,955] Trial 8 finished with value: 0.4909090909090909 and parameters: {'n_estimators': 55, 'learning_rate': 0.05153563898940156, 'max_depth': 10}. Best is trial 6 with value: 0.5181818181818182.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:38,130] Trial 9 finished with value: 0.509090909090909 and parameters: {'n_estimators': 114, 'learning_rate': 0.024308230835865294, 'max_depth': 7}. Best is trial 6 with value: 0.5181818181818182.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:38,465] Trial 10 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 50, 'learning_rate': 0.002594332646566443, 'max_depth': 3}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:38,781] Trial 11 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 50, 'learning_rate': 0.0024104799295341477, 'max_depth': 3}. Best is trial 10 with value: 0.5727272727272726.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:39,185] Trial 12 finished with value: 0.5909090909090909 and parameters: {'n_estimators': 79, 'learning_rate': 0.0020868952697788933, 'max_depth': 3}. Best is trial 12 with value: 0.5909090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:39,582] Trial 13 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 82, 'learning_rate': 0.0010879327662578974, 'max_depth': 3}. Best is trial 12 with value: 0.5909090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:40,113] Trial 14 finished with value: 0.5181818181818182 and parameters: {'n_estimators': 73, 'learning_rate': 0.0038552990649383034, 'max_depth': 5}. Best is trial 12 with value: 0.5909090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:40,935] Trial 15 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 139, 'learning_rate': 0.0033503129866204275, 'max_depth': 4}. Best is trial 12 with value: 0.5909090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:41,615] Trial 16 finished with value: 0.5272727272727272 and parameters: {'n_estimators': 96, 'learning_rate': 0.0012132587602841248, 'max_depth': 5}. Best is trial 12 with value: 0.5909090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:42,024] Trial 17 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 67, 'learning_rate': 0.005672168806234595, 'max_depth': 4}. Best is trial 12 with value: 0.5909090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:42,680] Trial 18 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 97, 'learning_rate': 0.001891785479690618, 'max_depth': 4}. Best is trial 12 with value: 0.5909090909090909.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:43,371] Trial 19 finished with value: 0.6363636363636364 and parameters: {'n_estimators': 145, 'learning_rate': 0.00601332303173029, 'max_depth': 3}. Best is trial 19 with value: 0.6363636363636364.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:44,888] Trial 20 finished with value: 0.5363636363636364 and parameters: {'n_estimators': 161, 'learning_rate': 0.0050410511011661765, 'max_depth': 6}. Best is trial 19 with value: 0.6363636363636364.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:45,621] Trial 21 finished with value: 0.6545454545454545 and parameters: {'n_estimators': 145, 'learning_rate': 0.0018008492127164623, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:46,384] Trial 22 finished with value: 0.6545454545454545 and parameters: {'n_estimators': 147, 'learning_rate': 0.0015383292712383416, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:47,323] Trial 23 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 152, 'learning_rate': 0.0016471269277012872, 'max_depth': 4}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:48,110] Trial 24 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 141, 'learning_rate': 0.0074292819481024215, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:49,479] Trial 25 finished with value: 0.509090909090909 and parameters: {'n_estimators': 182, 'learning_rate': 0.0888296220608064, 'max_depth': 4}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:50,980] Trial 26 finished with value: 0.5272727272727272 and parameters: {'n_estimators': 172, 'learning_rate': 0.001369070011373175, 'max_depth': 6}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:52,565] Trial 27 finished with value: 0.5272727272727272 and parameters: {'n_estimators': 196, 'learning_rate': 0.0034172256742143648, 'max_depth': 5}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:53,310] Trial 28 finished with value: 0.5909090909090909 and parameters: {'n_estimators': 150, 'learning_rate': 0.0010033003865084222, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:54,159] Trial 29 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 126, 'learning_rate': 0.004848466063540795, 'max_depth': 4}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:54,901] Trial 30 finished with value: 0.6454545454545455 and parameters: {'n_estimators': 142, 'learning_rate': 0.0028608697436034334, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:55,665] Trial 31 finished with value: 0.6454545454545455 and parameters: {'n_estimators': 141, 'learning_rate': 0.002741218163633735, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:56,568] Trial 32 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 132, 'learning_rate': 0.0016322198792340348, 'max_depth': 4}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:57,403] Trial 33 finished with value: 0.6454545454545455 and parameters: {'n_estimators': 157, 'learning_rate': 0.002702049625234676, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:58,440] Trial 34 finished with value: 0.509090909090909 and parameters: {'n_estimators': 134, 'learning_rate': 0.001444789434715574, 'max_depth': 5}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:59,068] Trial 35 finished with value: 0.6454545454545455 and parameters: {'n_estimators': 122, 'learning_rate': 0.0037669595295594643, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:39:59,831] Trial 36 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 105, 'learning_rate': 0.0020560786109780596, 'max_depth': 4}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:01,755] Trial 37 finished with value: 0.4909090909090909 and parameters: {'n_estimators': 162, 'learning_rate': 0.0026395175917328447, 'max_depth': 8}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:02,677] Trial 38 finished with value: 0.6545454545454545 and parameters: {'n_estimators': 173, 'learning_rate': 0.0017634076802034895, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:04,337] Trial 39 finished with value: 0.5181818181818182 and parameters: {'n_estimators': 176, 'learning_rate': 0.0017079782095755884, 'max_depth': 6}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:06,149] Trial 40 finished with value: 0.5181818181818182 and parameters: {'n_estimators': 196, 'learning_rate': 0.0013900846469903473, 'max_depth': 5}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:07,015] Trial 41 finished with value: 0.6545454545454545 and parameters: {'n_estimators': 149, 'learning_rate': 0.0022249493653239963, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:07,721] Trial 42 finished with value: 0.5909090909090909 and parameters: {'n_estimators': 151, 'learning_rate': 0.00124500546772214, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:08,846] Trial 43 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 166, 'learning_rate': 0.0019906110197353845, 'max_depth': 4}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:09,415] Trial 44 finished with value: 0.6 and parameters: {'n_estimators': 121, 'learning_rate': 0.013692241472366905, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:10,238] Trial 45 finished with value: 0.6363636363636364 and parameters: {'n_estimators': 184, 'learning_rate': 0.0031568908453188313, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:11,102] Trial 46 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 155, 'learning_rate': 0.002392103017342206, 'max_depth': 4}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:12,781] Trial 47 finished with value: 0.4909090909090909 and parameters: {'n_estimators': 146, 'learning_rate': 0.04026721124765877, 'max_depth': 9}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:13,587] Trial 48 finished with value: 0.6272727272727272 and parameters: {'n_estimators': 178, 'learning_rate': 0.004335376600712071, 'max_depth': 3}. Best is trial 21 with value: 0.6545454545454545.\n",
      "/tmp/ipykernel_126459/3921708413.py:53: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:14,401] Trial 49 finished with value: 0.5545454545454545 and parameters: {'n_estimators': 136, 'learning_rate': 0.0021952916911725695, 'max_depth': 4}. Best is trial 21 with value: 0.6545454545454545.\n",
      "[I 2024-08-08 23:40:14,403] A new study created in memory with name: no-name-ebe889e9-69cb-4e9b-be20-94cf87891ea2\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:26,912] Trial 0 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 189, 'learning_rate': 0.0016879163245775873, 'max_depth': 3}. Best is trial 0 with value: 0.5999999999999999.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:31,368] Trial 1 finished with value: 0.6 and parameters: {'n_estimators': 68, 'learning_rate': 0.026206755321691363, 'max_depth': 3}. Best is trial 1 with value: 0.6.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:39,937] Trial 2 finished with value: 0.5181818181818182 and parameters: {'n_estimators': 65, 'learning_rate': 0.04860109968780094, 'max_depth': 10}. Best is trial 1 with value: 0.6.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:40:53,950] Trial 3 finished with value: 0.5545454545454545 and parameters: {'n_estimators': 138, 'learning_rate': 0.01881333862933235, 'max_depth': 5}. Best is trial 1 with value: 0.6.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:41:17,226] Trial 4 finished with value: 0.5363636363636364 and parameters: {'n_estimators': 179, 'learning_rate': 0.0071071574572012484, 'max_depth': 8}. Best is trial 1 with value: 0.6.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:41:32,561] Trial 5 finished with value: 0.5272727272727272 and parameters: {'n_estimators': 117, 'learning_rate': 0.010348632455189858, 'max_depth': 9}. Best is trial 1 with value: 0.6.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:41:39,243] Trial 6 finished with value: 0.5363636363636364 and parameters: {'n_estimators': 50, 'learning_rate': 0.04187055535506402, 'max_depth': 9}. Best is trial 1 with value: 0.6.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:41:45,563] Trial 7 finished with value: 0.5545454545454545 and parameters: {'n_estimators': 96, 'learning_rate': 0.07257079115335721, 'max_depth': 3}. Best is trial 1 with value: 0.6.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:41:58,532] Trial 8 finished with value: 0.6181818181818182 and parameters: {'n_estimators': 147, 'learning_rate': 0.004464883843198102, 'max_depth': 4}. Best is trial 8 with value: 0.6181818181818182.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:42:07,062] Trial 9 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 84, 'learning_rate': 0.009727718729578751, 'max_depth': 5}. Best is trial 8 with value: 0.6181818181818182.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:42:25,374] Trial 10 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 149, 'learning_rate': 0.001686458981821835, 'max_depth': 6}. Best is trial 8 with value: 0.6181818181818182.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:42:38,993] Trial 11 finished with value: 0.6181818181818182 and parameters: {'n_estimators': 158, 'learning_rate': 0.003845839630331389, 'max_depth': 4}. Best is trial 8 with value: 0.6181818181818182.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:42:55,752] Trial 12 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 162, 'learning_rate': 0.0033148900089023624, 'max_depth': 5}. Best is trial 8 with value: 0.6181818181818182.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:43:05,890] Trial 13 finished with value: 0.6272727272727272 and parameters: {'n_estimators': 121, 'learning_rate': 0.004294969378068396, 'max_depth': 4}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:43:21,049] Trial 14 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 118, 'learning_rate': 0.0038683413199630027, 'max_depth': 7}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:43:31,984] Trial 15 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 128, 'learning_rate': 0.0012421795359605103, 'max_depth': 4}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:43:44,722] Trial 16 finished with value: 0.5636363636363636 and parameters: {'n_estimators': 104, 'learning_rate': 0.0058908483103306975, 'max_depth': 6}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:43:58,713] Trial 17 finished with value: 0.6181818181818182 and parameters: {'n_estimators': 169, 'learning_rate': 0.002515188166271397, 'max_depth': 4}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:44:10,374] Trial 18 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 141, 'learning_rate': 0.010990557150212124, 'max_depth': 4}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:44:34,851] Trial 19 finished with value: 0.5181818181818182 and parameters: {'n_estimators': 193, 'learning_rate': 0.005257450907391245, 'max_depth': 7}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:44:45,337] Trial 20 finished with value: 0.5545454545454545 and parameters: {'n_estimators': 101, 'learning_rate': 0.01706927177022703, 'max_depth': 5}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:44:58,122] Trial 21 finished with value: 0.609090909090909 and parameters: {'n_estimators': 154, 'learning_rate': 0.002645279298640304, 'max_depth': 4}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:45:06,609] Trial 22 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 130, 'learning_rate': 0.0037651502066657796, 'max_depth': 3}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:45:21,579] Trial 23 finished with value: 0.609090909090909 and parameters: {'n_estimators': 171, 'learning_rate': 0.004882822902151948, 'max_depth': 4}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:45:40,608] Trial 24 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 155, 'learning_rate': 0.0019524688594389759, 'max_depth': 6}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:45:55,828] Trial 25 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 142, 'learning_rate': 0.0011186043689294324, 'max_depth': 5}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:46:05,475] Trial 26 finished with value: 0.609090909090909 and parameters: {'n_estimators': 116, 'learning_rate': 0.0070092319441437834, 'max_depth': 4}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:46:17,614] Trial 27 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 182, 'learning_rate': 0.0026876097729763193, 'max_depth': 3}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:46:37,317] Trial 28 finished with value: 0.5272727272727272 and parameters: {'n_estimators': 163, 'learning_rate': 0.008355855434591587, 'max_depth': 6}. Best is trial 13 with value: 0.6272727272727272.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:46:46,402] Trial 29 finished with value: 0.6454545454545455 and parameters: {'n_estimators': 132, 'learning_rate': 0.014176017875423436, 'max_depth': 3}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:46:55,307] Trial 30 finished with value: 0.6363636363636364 and parameters: {'n_estimators': 133, 'learning_rate': 0.015095615135567337, 'max_depth': 3}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:47:04,254] Trial 31 finished with value: 0.6 and parameters: {'n_estimators': 131, 'learning_rate': 0.01686007572296209, 'max_depth': 3}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:47:11,604] Trial 32 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 110, 'learning_rate': 0.026935190574421113, 'max_depth': 3}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:47:17,732] Trial 33 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 92, 'learning_rate': 0.012849140473887223, 'max_depth': 3}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:47:26,702] Trial 34 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 136, 'learning_rate': 0.02241357175983952, 'max_depth': 3}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:47:38,648] Trial 35 finished with value: 0.5545454545454545 and parameters: {'n_estimators': 146, 'learning_rate': 0.013184139372179868, 'max_depth': 4}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:47:46,575] Trial 36 finished with value: 0.5999999999999999 and parameters: {'n_estimators': 124, 'learning_rate': 0.02931635639978377, 'max_depth': 3}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:47:54,461] Trial 37 finished with value: 0.5454545454545454 and parameters: {'n_estimators': 79, 'learning_rate': 0.04032523590903345, 'max_depth': 5}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:48:10,106] Trial 38 finished with value: 0.5181818181818182 and parameters: {'n_estimators': 122, 'learning_rate': 0.007367748025754386, 'max_depth': 10}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:48:18,699] Trial 39 finished with value: 0.6454545454545455 and parameters: {'n_estimators': 135, 'learning_rate': 0.014275779930422134, 'max_depth': 3}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:48:25,833] Trial 40 finished with value: 0.5545454545454545 and parameters: {'n_estimators': 111, 'learning_rate': 0.0964061848065995, 'max_depth': 3}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:48:36,843] Trial 41 finished with value: 0.5545454545454545 and parameters: {'n_estimators': 134, 'learning_rate': 0.014039197503368111, 'max_depth': 4}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:48:46,445] Trial 42 finished with value: 0.5818181818181818 and parameters: {'n_estimators': 148, 'learning_rate': 0.020603496876805242, 'max_depth': 3}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:48:55,429] Trial 43 finished with value: 0.5727272727272726 and parameters: {'n_estimators': 139, 'learning_rate': 0.03282878449156662, 'max_depth': 3}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:49:05,419] Trial 44 finished with value: 0.6 and parameters: {'n_estimators': 121, 'learning_rate': 0.00927118934623529, 'max_depth': 4}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:49:20,909] Trial 45 finished with value: 0.5363636363636364 and parameters: {'n_estimators': 111, 'learning_rate': 0.01133402181458555, 'max_depth': 8}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:49:36,445] Trial 46 finished with value: 0.5545454545454545 and parameters: {'n_estimators': 151, 'learning_rate': 0.015252530015411936, 'max_depth': 5}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:49:46,986] Trial 47 finished with value: 0.609090909090909 and parameters: {'n_estimators': 126, 'learning_rate': 0.006511587825485434, 'max_depth': 4}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:49:56,485] Trial 48 finished with value: 0.5909090909090908 and parameters: {'n_estimators': 145, 'learning_rate': 0.004868089471168329, 'max_depth': 3}. Best is trial 29 with value: 0.6454545454545455.\n",
      "/tmp/ipykernel_126459/3921708413.py:64: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
      "[I 2024-08-08 23:50:10,126] Trial 49 finished with value: 0.5454545454545454 and parameters: {'n_estimators': 135, 'learning_rate': 0.022857590093103848, 'max_depth': 5}. Best is trial 29 with value: 0.6454545454545455.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier with Optimized Base Models\n",
      "Accuracy: 0.6428571428571429\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62        14\n",
      "           1       0.62      0.71      0.67        14\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.65      0.64      0.64        28\n",
      "weighted avg       0.65      0.64      0.64        28\n",
      "\n",
      "Cross-Validation Accuracy for Stacking Classifier: 0.5949735449735449 ± 0.046821660090640906\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['stacking_classifier_optimized_2024-08-08_23-51-26.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the objective functions for each base model\n",
    "def objective_lr(trial):\n",
    "    param_grid = {\n",
    "        'C': trial.suggest_loguniform('C', 1e-5, 1e2),\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l2']),\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs']),\n",
    "    }\n",
    "    pipeline = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "    return cross_val_score(pipeline, X_train, y_train, cv=StratifiedKFold(5)).mean()\n",
    "\n",
    "def objective_rf(trial):\n",
    "    param_grid = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 30),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n",
    "    }\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', RandomForestClassifier(random_state=42, **param_grid))\n",
    "    ])\n",
    "    return cross_val_score(pipeline, X_train, y_train, cv=StratifiedKFold(5)).mean()\n",
    "\n",
    "def objective_svm(trial):\n",
    "    param_grid = {\n",
    "        'C': trial.suggest_loguniform('C', 1e-3, 1e2),\n",
    "        'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf']),\n",
    "    }\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', SVC(random_state=42, **param_grid))\n",
    "    ])\n",
    "    return cross_val_score(pipeline, X_train, y_train, cv=StratifiedKFold(5)).mean()\n",
    "\n",
    "def objective_gb(trial):\n",
    "    param_grid = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "    }\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', GradientBoostingClassifier(random_state=42, **param_grid))\n",
    "    ])\n",
    "    return cross_val_score(pipeline, X_train, y_train, cv=StratifiedKFold(5)).mean()\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    param_grid = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "    }\n",
    "    pipeline = Pipeline([\n",
    "        ('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', **param_grid))\n",
    "    ])\n",
    "    return cross_val_score(pipeline, X_train, y_train, cv=StratifiedKFold(5)).mean()\n",
    "\n",
    "# Run Optuna studies for each base model\n",
    "studies = {}\n",
    "for model_name, objective in zip(\n",
    "    ['LogisticRegression', 'RandomForest', 'SVM', 'GradientBoosting', 'XGBoost'],\n",
    "    [objective_lr, objective_rf, objective_svm, objective_gb, objective_xgb]\n",
    "):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    studies[model_name] = study.best_params\n",
    "\n",
    "# Define the optimized base models\n",
    "optimized_base_models = [\n",
    "    ('lr', Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=1000, random_state=42, **studies['LogisticRegression']))])),\n",
    "    ('rf', Pipeline([('clf', RandomForestClassifier(random_state=42, **studies['RandomForest']))])),\n",
    "    ('svm', Pipeline([('scaler', StandardScaler()), ('clf', SVC(random_state=42, **studies['SVM']))])),\n",
    "    ('gb', Pipeline([('clf', GradientBoostingClassifier(random_state=42, **studies['GradientBoosting']))])),\n",
    "    ('xgb', Pipeline([('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', **studies['XGBoost']))]))\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Stacking Classifier with optimized base models\n",
    "stacking_clf = StackingClassifier(estimators=optimized_base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Train and evaluate the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Stacking Classifier with Optimized Base Models\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Cross-Validation for Stacking Classifier\n",
    "cv_scores = cross_val_score(stacking_clf, X_res, y_res, cv=StratifiedKFold(5))\n",
    "print(f\"Cross-Validation Accuracy for Stacking Classifier: {cv_scores.mean()} ± {cv_scores.std()}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Save the stacking classifier\n",
    "date_time = pd.Timestamp.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "joblib.dump(stacking_clf, f'../models/stacking_classifier_optimized_{date_time}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOA8bdRDz91X"
   },
   "source": [
    "# Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vrz5KfPsz-3Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Model\n",
      "Accuracy: 0.6785714285714286\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.57      0.64        14\n",
      "           1       0.65      0.79      0.71        14\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.69      0.68      0.67        28\n",
      "weighted avg       0.69      0.68      0.67        28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/happy-ml/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy for Stacking Classifier: 0.6013227513227513 ± 0.06458278303121939\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAHFCAYAAACn7hC1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxgklEQVR4nO3deXQUZdr38V8nJE0CJBIgCWGIQFhkJyxiUGRHQ0R5RgVEHZBFFh1BkOFBBxJFCTAeQXbZEZTlkWXAURRBQIagCYKCOiK7KBFBZYnQhKTeP3zJ2KaDSVGVDuX346lz6Luq674qZ5hcXNddVS7DMAwBAACYEODvAAAAwPWLRAIAAJhGIgEAAEwjkQAAAKaRSAAAANNIJAAAgGkkEgAAwDQSCQAAYBqJBAAAMI1EAo726aef6pFHHlH16tVVunRplS1bVk2bNtWkSZP0ww8/2Dr37t271aZNG4WHh8vlcmnKlCmWz+FyuZSSkmL5eX/PokWL5HK55HK5tGXLlnz7DcNQzZo15XK51LZtW1NzzJw5U4sWLSrSd7Zs2VJgTADsUcrfAQB2mTt3roYMGaI6depo5MiRqlevnrKzs5WRkaHZs2crLS1Na9assW3+vn37KisrS8uXL1f58uVVrVo1y+dIS0vTn/70J8vPW1jlypXT/Pnz8yULW7du1cGDB1WuXDnT5545c6YqVqyoPn36FPo7TZs2VVpamurVq2d6XgBFQyIBR0pLS9PgwYPVqVMnrV27Vm63O29fp06dNGLECG3YsMHWGPbt26cBAwYoMTHRtjluueUW285dGD169NBrr72mGTNmKCwsLG98/vz5SkhI0NmzZ4sljuzsbLlcLoWFhfn9ZwL80dDagCONHz9eLpdLc+bM8UoirggODtbdd9+d9zk3N1eTJk3STTfdJLfbrcjISP3lL3/R8ePHvb7Xtm1bNWjQQOnp6WrdurVCQ0NVo0YNTZgwQbm5uZL+W/a/fPmyZs2aldcCkKSUlJS8P//ale8cOXIkb2zz5s1q27atKlSooJCQEMXGxuree+/Vzz//nHeMr9bGvn37dM8996h8+fIqXbq0mjRposWLF3sdc6UFsGzZMj3zzDOKiYlRWFiYOnbsqC+//LJwP2RJDzzwgCRp2bJleWNnzpzRqlWr1LdvX5/fefbZZ9WyZUtFREQoLCxMTZs21fz58/Xr9wdWq1ZNn332mbZu3Zr387tS0bkS+5IlSzRixAhVqVJFbrdbBw4cyNfaOHXqlKpWrapWrVopOzs77/yff/65ypQpo4cffrjQ1wrANxIJOE5OTo42b96sZs2aqWrVqoX6zuDBgzVq1Ch16tRJ69at07hx47Rhwwa1atVKp06d8jo2MzNTDz74oB566CGtW7dOiYmJGj16tJYuXSpJSkpKUlpamiTpvvvuU1paWt7nwjpy5IiSkpIUHBysBQsWaMOGDZowYYLKlCmjS5cuFfi9L7/8Uq1atdJnn32mqVOnavXq1apXr5769OmjSZMm5Tv+6aef1tGjRzVv3jzNmTNHX331lbp27aqcnJxCxRkWFqb77rtPCxYsyBtbtmyZAgIC1KNHjwKvbeDAgVq5cqVWr16tP//5z/rrX/+qcePG5R2zZs0a1ahRQ/Hx8Xk/v9+2oUaPHq1jx45p9uzZWr9+vSIjI/PNVbFiRS1fvlzp6ekaNWqUJOnnn3/W/fffr9jYWM2ePbtQ1wngKgzAYTIzMw1JRs+ePQt1/BdffGFIMoYMGeI1/uGHHxqSjKeffjpvrE2bNoYk48MPP/Q6tl69esYdd9zhNSbJeOyxx7zGkpOTDV9/7RYuXGhIMg4fPmwYhmG88cYbhiRjz549V41dkpGcnJz3uWfPnobb7TaOHTvmdVxiYqIRGhpq/PTTT4ZhGMb7779vSDK6dOniddzKlSsNSUZaWtpV570Sb3p6et659u3bZxiGYbRo0cLo06ePYRiGUb9+faNNmzYFnicnJ8fIzs42nnvuOaNChQpGbm5u3r6Cvntlvttvv73Afe+//77X+MSJEw1Jxpo1a4zevXsbISEhxqeffnrVawRQOFQk8If3/vvvS1K+RX0333yz6tatq02bNnmNR0dH6+abb/Yaa9SokY4ePWpZTE2aNFFwcLAeffRRLV68WIcOHSrU9zZv3qwOHTrkq8T06dNHP//8c77KyK/bO9Iv1yGpSNfSpk0bxcXFacGCBdq7d6/S09MLbGtcibFjx44KDw9XYGCggoKCNHbsWJ0+fVonT54s9Lz33ntvoY8dOXKkkpKS9MADD2jx4sWaNm2aGjZsWOjvAygYiQQcp2LFigoNDdXhw4cLdfzp06clSZUrV863LyYmJm//FRUqVMh3nNvt1oULF0xE61tcXJzee+89RUZG6rHHHlNcXJzi4uL08ssvX/V7p0+fLvA6ruz/td9ey5X1JEW5FpfLpUceeURLly7V7NmzVbt2bbVu3drnsR999JE6d+4s6Ze7av79738rPT1dzzzzTJHn9XWdV4uxT58+unjxoqKjo1kbAViIRAKOExgYqA4dOmjXrl35Fkv6cuWX6YkTJ/Lt+/bbb1WxYkXLYitdurQkyePxeI3/dh2GJLVu3Vrr16/XmTNntHPnTiUkJGjYsGFavnx5geevUKFCgdchydJr+bU+ffro1KlTmj17th555JECj1u+fLmCgoL05ptvqnv37mrVqpWaN29uak5fi1YLcuLECT322GNq0qSJTp8+raeeesrUnADyI5GAI40ePVqGYWjAgAE+FydmZ2dr/fr1kqT27dtLUt5iySvS09P1xRdfqEOHDpbFdeXOg08//dRr/EosvgQGBqply5aaMWOGJOnjjz8u8NgOHTpo8+bNeYnDFa+++qpCQ0NtuzWySpUqGjlypLp27arevXsXeJzL5VKpUqUUGBiYN3bhwgUtWbIk37FWVXlycnL0wAMPyOVy6e2331ZqaqqmTZum1atXX/O5AfAcCThUQkKCZs2apSFDhqhZs2YaPHiw6tevr+zsbO3evVtz5sxRgwYN1LVrV9WpU0ePPvqopk2bpoCAACUmJurIkSMaM2aMqlatqieffNKyuLp06aKIiAj169dPzz33nEqVKqVFixbp66+/9jpu9uzZ2rx5s5KSkhQbG6uLFy/m3RnRsWPHAs+fnJysN998U+3atdPYsWMVERGh1157Tf/61780adIkhYeHW3YtvzVhwoTfPSYpKUkvvfSSevXqpUcffVSnT5/Wiy++6PMW3YYNG2r58uVasWKFatSoodKlS5ta15CcnKwPPvhA7777rqKjozVixAht3bpV/fr1U3x8vKpXr17kcwL4LxIJONaAAQN08803a/LkyZo4caIyMzMVFBSk2rVrq1evXnr88cfzjp01a5bi4uI0f/58zZgxQ+Hh4brzzjuVmprqc02EWWFhYdqwYYOGDRumhx56SDfccIP69++vxMRE9e/fP++4Jk2a6N1331VycrIyMzNVtmxZNWjQQOvWrctbY+BLnTp1tGPHDj399NN67LHHdOHCBdWtW1cLFy4s0hMi7dK+fXstWLBAEydOVNeuXVWlShUNGDBAkZGR6tevn9exzz77rE6cOKEBAwbo3LlzuvHGG72es1EYGzduVGpqqsaMGeNVWVq0aJHi4+PVo0cPbd++XcHBwVZcHvCH5DKMXz0FBgAAoAhYIwEAAEwjkQAAAKaRSAAAANNIJAAAcKht27apa9euiomJkcvl0tq1a732r169WnfccYcqVqwol8ulPXv2FHkOEgkAABwqKytLjRs31vTp0wvcf+uttxbq9u2CcPsnAAAOlZiYqMTExAL3X3lcfFFvrf41EgkAAK4THo8n3yP23W63z4e6FRdHJhLtp6b9/kHAH9BDCVX8HQJQ4vRtEWv7HCHxj//+QYUw6p6KevbZZ73GkpOTlZKSYsn5zXBkIgEAgBONHj1aw4cP9xrzZzVCIpEAAMB+LmvubfB3G8MXEgkAAOxWhNfeX29IJAAAsJtFFYmiOn/+vA4cOJD3+fDhw9qzZ48iIiIUGxurH374QceOHdO3334rSfryyy8lSdHR0YqOji7UHDxHAgAAh8rIyFB8fLzi4+MlScOHD1d8fLzGjh0rSVq3bp3i4+OVlJQkSerZs6fi4+M1e/bsQs9BRQIAALv5qbXRtm1bXe0l33369FGfPn2uaQ4SCQAA7Oan1kZxcO6VAQAA21GRAADAbty1AQAATKO1AQAAkB8VCQAA7EZrAwAAmEZrAwAAID8qEgAA2I3WBgAAMM3BrQ0SCQAA7ObgioRzUyQAAGA7KhIAANiN1gYAADDNwYmEc68MAADYjooEAAB2C3DuYksSCQAA7EZrAwAAID8qEgAA2M3Bz5EgkQAAwG60NgAAAPKjIgEAgN1obQAAANMc3NogkQAAwG4Orkg4N0UCAAC2oyIBAIDdaG0AAADTaG0AAADkR0UCAAC70doAAACm0doAAADIj4oEAAB2o7UBAABMc3Ai4dwrAwAAtqMiAQCA3VhsCQAATHMFWLMV0bZt29S1a1fFxMTI5XJp7dq1XvsNw1BKSopiYmIUEhKitm3b6rPPPivSHCQSAADYzeWyZiuirKwsNW7cWNOnT/e5f9KkSXrppZc0ffp0paenKzo6Wp06ddK5c+cKPQetDQAAHCoxMVGJiYk+9xmGoSlTpuiZZ57Rn//8Z0nS4sWLFRUVpddff10DBw4s1BxUJAAAsJtFrQ2Px6OzZ896bR6Px1RIhw8fVmZmpjp37pw35na71aZNG+3YsaPQ5yGRAADAbha1NlJTUxUeHu61paammgopMzNTkhQVFeU1HhUVlbevMGhtAABwnRg9erSGDx/uNeZ2u6/pnK7frL0wDCPf2NWQSAAAYLOi/GK+Grfbfc2JwxXR0dGSfqlMVK5cOW/85MmT+aoUV0NrAwAAm7lcLks2K1WvXl3R0dHauHFj3tilS5e0detWtWrVqtDnoSIBAIBDnT9/XgcOHMj7fPjwYe3Zs0cRERGKjY3VsGHDNH78eNWqVUu1atXS+PHjFRoaql69ehV6DhIJAADs5qcHW2ZkZKhdu3Z5n6+sr+jdu7cWLVqkv/3tb7pw4YKGDBmiH3/8US1bttS7776rcuXKFXoOEgkAAGxmdVuisNq2bSvDMArc73K5lJKSopSUFNNzsEYCAACYRkUCAACb+asiURxIJAAAsBmJBAAAMM3JiQRrJAAAgGlUJAAAsJtzCxIkEgAA2I3WBgAAgA9UJAAAsJmTKxIkEgAA2MzJiQStDQAAYBoVCQAAbObkigSJBAAAdnNuHkFrAwAAmEdFAgAAm9HaAAAAppFIAAAA05ycSLBGAgAAmEZFAgAAuzm3IEEiAQCA3WhtAAAA+EBFAgAAmzm5IkEiAQCAzZycSNDaAAAAplGRAADAZk6uSJBIAABgN+fmEbQ2AACAeVQkAACwGa0NAABgGokEAAAwzcmJBGskAACAaVQkAACwm3MLEiQSAADYjdYGAACAD1QkYLkAl9SnZVV1qFNREWWCdTrrkt754nst/ei4DH8HB/jRuR9OacvyeTr06Ue6fOmSIqKrKHHACEVXr+3v0GAzJ1ckSCRguQeaVVHXhlGasPGAjpy+oDpRZfS3jjWV5bms1Z9k+js8wC8uZp3T0ueGKbZuY90/crzKhN2gH7/7Vu7Qsv4ODcXAX4nEuXPnNGbMGK1Zs0YnT55UfHy8Xn75ZbVo0cKyOUgkYLl6lcvp34d+1IdHfpIkfXfOo/a1f1KdKP4PE39cO9evUFhEJSUNHJk3Fl4p2o8R4Y+gf//+2rdvn5YsWaKYmBgtXbpUHTt21Oeff64qVapYModfE4njx49r1qxZ2rFjhzIzM+VyuRQVFaVWrVpp0KBBqlq1qj/Dg0n7vj2rrg2j9KcbSuv4TxdVo2KoGsSU08xtR/wdGuA3Bz5OU/VGzbV26nP6+j97VbZ8BcV3vFtN2nXxd2goBv6oSFy4cEGrVq3SP//5T91+++2SpJSUFK1du1azZs3S888/b8k8fksktm/frsTERFWtWlWdO3dW586dZRiGTp48qbVr12ratGl6++23deutt/orRJi0bNe3KuMupUUPN1FurqGAAJfmpx3T5v2n/R0a4Dc/fX9CuzetV4s771XC3b104uB/tOnVGSpVKkgNWnfyd3iwmx86G5cvX1ZOTo5Kly7tNR4SEqLt27dbNo/fEoknn3xS/fv31+TJkwvcP2zYMKWnp1/1PB6PRx6Px2ss9/IlBZQKtixWFE27WhXUsU5FvbDhKx354YJqVgrVkNbVdPp8tt79z/f+Dg/wCyPXUHSN2mrTo58kKapaTZ365qh2b1pPIoFC8/U7z+12y+125zu2XLlySkhI0Lhx41S3bl1FRUVp2bJl+vDDD1WrVi3LYvLb7Z/79u3ToEGDCtw/cOBA7du373fPk5qaqvDwcK/t6MZXrQwVRTTwthu1bNc3ev+r0zp8+mdt/M8prdpzQr2aW9OPA65HZW+IUMWYWK+xCjGxOnv6pJ8iQnFyuVyWbL5+56WmphY475IlS2QYhqpUqSK3262pU6eqV69eCgwMtOza/JZIVK5cWTt27Chwf1pamipXrvy75xk9erTOnDnjtd3Y6S9WhooicpcKkPGb+zxzDEMOvvsJ+F1VatfXDyeOe439kHlcYRWj/BQRipNViYSv33mjR48ucN64uDht3bpV58+f19dff62PPvpI2dnZql69umXX5rfWxlNPPaVBgwZp165d6tSpk6KiouRyuZSZmamNGzdq3rx5mjJlyu+ex1dJh7aGf6Ud/lEPtqii7855dOT0BdWqVEb3x8fo7c/4lxf+uFrcea+WPjdUaf98XTe1bKMTh77UJ++/pTv6DvN3aCgGVv1DqqA2xu8pU6aMypQpox9//FHvvPOOJk2aZE1AklyG8dt/OxafFStWaPLkydq1a5dycnIkSYGBgWrWrJmGDx+u7t27mzpv+6lpVoaJIgoJClDfW2J1W1yEbggN0umsS9r85Sm9+tFxXc7lkVT+9FAC7SV/OrB7p7aumK8fv/tG4ZWi1SLxPu7aKAH6toj9/YOuUc2n3rbkPAdeTCzS8e+8844Mw1CdOnV04MABjRw5Um63W9u3b1dQUJAlMfn19s8ePXqoR48eys7O1qlTpyRJFStWtOzi4B8XsnM144MjmvHBEX+HApQoNeNvUc34W/wdBvzAXw+kutL6OH78uCIiInTvvffqhRdesPT3bIl4IFVQUFCh1kMAAHA98tcase7du5uu7hcWL+0CAACmlYiKBAAATsZLuwAAgGkOziNobQAAAPOoSAAAYLOAAOeWJEgkAACwGa0NAAAAH6hIAABgM+7aAAAApjk4jyCRAADAbk6uSLBGAgAAmEZFAgAAmzm5IkEiAQCAzRycR9DaAAAA5lGRAADAZrQ2AACAaQ7OI2htAAAA86hIAABgM1obAADANAfnEbQ2AACAeVQkAACwGa0NAABgmoPzCBIJAADs5uSKBGskAACAaVQkAACwmYMLEiQSAADYjdYGAACAD1QkAACwmYMLEiQSAADYjdYGAACAD1QkAACwmYMLEiQSAADYjdYGAACAD1QkAACwmZMrEiQSAADYzMF5BK0NAADs5nK5LNmK4vLly/r73/+u6tWrKyQkRDVq1NBzzz2n3NxcS6+NigQAAA40ceJEzZ49W4sXL1b9+vWVkZGhRx55ROHh4Ro6dKhl85BIAABgM3+0NtLS0nTPPfcoKSlJklStWjUtW7ZMGRkZls5DawMAAJv5o7Vx2223adOmTdq/f78k6ZNPPtH27dvVpUsXS6+NigQAANcJj8cjj8fjNeZ2u+V2u/MdO2rUKJ05c0Y33XSTAgMDlZOToxdeeEEPPPCApTFRkQAAwGYulzVbamqqwsPDvbbU1FSfc65YsUJLly7V66+/ro8//liLFy/Wiy++qMWLF1t6bVQkAACwWYBFiyRGjx6t4cOHe435qkZI0siRI/W///u/6tmzpySpYcOGOnr0qFJTU9W7d29L4pFIJAAAuG4U1Mbw5eeff1ZAgHfjITAwkNs/AQC43vjjro2uXbvqhRdeUGxsrOrXr6/du3frpZdeUt++fS2dh0QCAACb+eMR2dOmTdOYMWM0ZMgQnTx5UjExMRo4cKDGjh1r6TwkEgAA2CzADxWJcuXKacqUKZoyZYqt83DXBgAAMI2KBAAANuPtnwAAwDQH5xG0NgAAgHlUJAAAsJlLzi1JkEgAAGAzf9y1UVxobQAAANOoSAAAYDPu2gAAAKY5OI+gtQEAAMyjIgEAgM2seo14SUQiAQCAzRycR5BIAABgNycvtmSNBAAAMI2KBAAANnNwQYJEAgAAuzl5sSWtDQAAYBoVCQAAbObcegSJBAAAtuOuDQAAAB+oSAAAYDMnv0a8UInEunXrCn3Cu+++23QwAAA4kZNbG4VKJLp161aok7lcLuXk5FxLPAAA4DpSqEQiNzfX7jgAAHAsBxckWCMBAIDd/vCtjd/KysrS1q1bdezYMV26dMlr3xNPPGFJYAAAOMUffrHlr+3evVtdunTRzz//rKysLEVEROjUqVMKDQ1VZGQkiQQAAH8gRX6OxJNPPqmuXbvqhx9+UEhIiHbu3KmjR4+qWbNmevHFF+2IEQCA65rL5bJkK4mKnEjs2bNHI0aMUGBgoAIDA+XxeFS1alVNmjRJTz/9tB0xAgBwXXNZtJVERU4kgoKC8rKiqKgoHTt2TJIUHh6e92cAAPDHUOQ1EvHx8crIyFDt2rXVrl07jR07VqdOndKSJUvUsGFDO2IEAOC6xmvEf2X8+PGqXLmyJGncuHGqUKGCBg8erJMnT2rOnDmWBwgAwPXO5bJmK4mKXJFo3rx53p8rVaqkt956y9KAAADA9YMHUgEAYLOSeseFFYqcSFSvXv2qP5BDhw5dU0AAADiNg/OIoicSw4YN8/qcnZ2t3bt3a8OGDRo5cqRVcQEAgOtAkROJoUOH+hyfMWOGMjIyrjkgAACcxh93bVSrVk1Hjx7NNz5kyBDNmDHDsnmKfNdGQRITE7Vq1SqrTgcAgGP4466N9PR0nThxIm/buHGjJOn++++39NosW2z5xhtvKCIiwqrTAQDgGP5YbFmpUiWvzxMmTFBcXJzatGlj6TymHkj16x+IYRjKzMzU999/r5kzZ1oaHAAA+C+PxyOPx+M15na75Xa7r/q9S5cuaenSpRo+fLjlSY3LMAyjKF9ISUnxCiIgIECVKlVS27ZtddNNN1kanFkXL/s7AqBkKt/icX+HAJQ4F3ZPt32Ov675wpLzVPhkhZ599lmvseTkZKWkpFz1eytXrlSvXr107NgxxcTEWBLLFUVOJK4HJBKAbyQSQH7FkUg8sfY/lpznH4nVTVUk7rjjDgUHB2v9+vWWxPFrRW5tBAYG6sSJE4qMjPQaP336tCIjI5WTk2NZcAAA4L8KkzT81tGjR/Xee+9p9erVtsRU5ESioAKGx+NRcHDwNQcEAIDTBPjxgVQLFy5UZGSkkpKSbDl/oROJqVOnSvpl5em8efNUtmzZvH05OTnatm1biVkjAQBASeKvRCI3N1cLFy5U7969VaqUPW/FKPRZJ0+eLOmXisTs2bMVGBiYty84OFjVqlXT7NmzrY8QAACY8t577+nYsWPq27evbXMUOpE4fPiwJKldu3ZavXq1ypcvb1tQAAA4ib9e2tW5c+cClyRYpch1jvfff9+OOAAAcCx/rpGwW5EfkX3fffdpwoQJ+cb/8Y9/WP7YTQAAULIVOZHYunWrz5Wfd955p7Zt22ZJUAAAOIk/3rVRXIrc2jh//rzP2zyDgoJ09uxZS4ICAMBJ/PH2z+JS5IpEgwYNtGLFinzjy5cvV7169SwJCgAAJwmwaCuJilyRGDNmjO69914dPHhQ7du3lyRt2rRJr7/+ut544w3LAwQAACVXkROJu+++W2vXrtX48eP1xhtvKCQkRI0bN9bmzZsVFhZmR4wAAFzXHNzZKHoiIUlJSUl5Cy5/+uknvfbaaxo2bJg++eQT3rUBAMBvsEbCh82bN+uhhx5STEyMpk+fri5duigjI8PK2AAAQAlXpIrE8ePHtWjRIi1YsEBZWVnq3r27srOztWrVKhZaAgBQAAcXJApfkejSpYvq1aunzz//XNOmTdO3336radOm2RkbAACOEOCyZiuJCl2RePfdd/XEE09o8ODBqlWrlp0xAQCA60ShKxIffPCBzp07p+bNm6tly5aaPn26vv/+eztjAwDAEQJcLku2kqjQiURCQoLmzp2rEydOaODAgVq+fLmqVKmi3Nxcbdy4UefOnbMzTgAArltOfkR2ke/aCA0NVd++fbV9+3bt3btXI0aM0IQJExQZGam7777bjhgBAEAJdU1P3KxTp44mTZqk48ePa9myZVbFBACAo7DY8ncEBgaqW7du6tatmxWnAwDAUVwqoVmABSxJJAAAQMFKajXBCiX1ZWIAAOA6QEUCAACbObkiQSIBAIDNXCX13k0L0NoAAACmUZEAAMBmtDYAAIBpDu5s0NoAAADmUZEAAMBmJfWFW1YgkQAAwGZOXiNBawMAAJhGRQIAAJs5uLNBIgEAgN0CeGkXAAAwy8kVCdZIAAAA06hIAABgMyfftUEiAQCAzZz8HAlaGwAAwDQSCQAAbOZyWbMV1TfffKOHHnpIFSpUUGhoqJo0aaJdu3ZZem20NgAAsJk/Whs//vijbr31VrVr105vv/22IiMjdfDgQd1www2WzkMiAQCAA02cOFFVq1bVwoUL88aqVatm+Ty0NgAAsJlVrQ2Px6OzZ896bR6Px+ec69atU/PmzXX//fcrMjJS8fHxmjt3ruXXRiIBAIDNAizaUlNTFR4e7rWlpqb6nPPQoUOaNWuWatWqpXfeeUeDBg3SE088oVdffdXSa3MZhmFYesYS4OJlf0cAlEzlWzzu7xCAEufC7um2z7Eo/Zgl53mgUVS+CoTb7Zbb7c53bHBwsJo3b64dO3bkjT3xxBNKT09XWlqaJfFIrJEAAMB2LosWWxaUNPhSuXJl1atXz2usbt26WrVqlSWxXEEiAQCAzfzxOKpbb71VX375pdfY/v37deONN1o6D4kEAAA288ftn08++aRatWql8ePHq3v37vroo480Z84czZkzx9J5WGwJAIADtWjRQmvWrNGyZcvUoEEDjRs3TlOmTNGDDz5o6TxUJAAAsJm/3rRx11136a677rJ1DhIJAABs5uB3dtHaAAAA5lGRAADAZlbd/lkSkUgAAGAzJ5f/nXxtAADAZlQkAACwGa0NAABgmnPTCFobAADgGlCRAADAZrQ2AACAaU4u/5NIAABgMydXJJycJAEAAJtRkQAAwGbOrUeQSAAAYDsHdzZobQAAAPOoSAAAYLMABzc3SCQAALAZrQ0AAAAfqEgAAGAzF60NAABgFq0NAAAAH6hIAABgM+7aAAAApjm5tUEiAQCAzZycSLBGAgAAmEZFAgAAm3H7JwAAMC3AuXkErQ0AAGAeFQkAAGxGawMAAJjGXRsAAAA+UJEAAMBmtDYAAIBp3LUBAADgAxUJWG7l8te1csUyffvNN5KkuJq1NHDwEN3Wuo2fIwOK161N4/TkXzqqab1YVa4Uru5PztH6LZ/m7b+nfWP1u/c2xdetqorly6plj1R9uv8bP0YMuzi5tUFFApaLjIrW0Cef0usrV+n1lat0c8tbNPTxx3TgwFf+Dg0oVmVC3Nq7/xs9OWGlz/2hIcFK++Sgxkz7ZzFHhuLmclmzFUVKSopcLpfXFh0dbfm1UZGA5dq2a+/1+a9Dn9TK5cv06Sd7VLNmLT9FBRS/d//9ud799+cF7l/2r3RJUmzliOIKCX7ir3pE/fr19d577+V9DgwMtHwOEgnYKicnR+++s0EXLvysxo3j/R0OAPyhlCpVypYqhNcctp79Gn399ddKTk7WggULCjzG4/HI4/F4jRmBbrndbrvDw1V8tf9LPdyrpy5d8ig0NFSTp85QXM2a/g4LAPwiwKInUvn6ned2F/w776uvvlJMTIzcbrdatmyp8ePHq0aNGpbEckWJXiPxww8/aPHixVc9JjU1VeHh4V7bPyamFlOEKEi1atW1ctVaLXl9he7v8YDGPD1KBw8c8HdYAOAXLos2X7/zUlN9/85r2bKlXn31Vb3zzjuaO3euMjMz1apVK50+fdrSa/NrRWLdunVX3X/o0KHfPcfo0aM1fPhwrzEjkGqEvwUFByv2xhslSfUbNNRn+/bqtaWvamzKc36ODACuX75+5xVUjUhMTMz7c8OGDZWQkKC4uDgtXrw43zmuhV8TiW7dusnlcskwjAKPcf1OOchXSefiZUvCg4UMw1D2pUv+DgMA/MOi1ZZXa2P8njJlyqhhw4b66itr76Dza2ujcuXKWrVqlXJzc31uH3/8sT/Dg0lTp7ykj3dl6Jtvjuur/V9q2suTlZH+kbrc1dXfoQHFqkxIsBrVrqJGtatIkqpVqaBGtauoanR5SVL5sFA1ql1FdeN+WQxXu1qUGtWuoqgK5fwWM+zhsui/a+HxePTFF1+ocuXKFl3VL/xakWjWrJk+/vhjdevWzef+36tWoGQ6ffqUnvnfv+n770+qbLlyql27jma+Mk8JrW71d2hAsWpa70a9O29o3udJT90rSVqybqceTV6qpDYNNfe5h/P2L5nYV5L0/Oy39MIrbxVvsHCcp556Sl27dlVsbKxOnjyp559/XmfPnlXv3r0tncdl+PE39QcffKCsrCzdeeedPvdnZWUpIyNDbdoU7YmItDYA38q3eNzfIQAlzoXd022f46NDZyw5z801wgt9bM+ePbVt2zadOnVKlSpV0i233KJx48apXr16lsRyhV8TCbuQSAC+kUgA+RVHIpFuUSLRogiJRHEp0bd/AgCAkq1EP5AKAABHcO47u0gkAACwm5Pf/kkiAQCAzSx6QnaJxBoJAABgGhUJAABs5uCCBIkEAAC2c3AmQWsDAACYRkUCAACbcdcGAAAwjbs2AAAAfKAiAQCAzRxckCCRAADAdg7OJGhtAAAA06hIAABgM+7aAAAApjn5rg0SCQAAbObgPII1EgAAwDwqEgAA2M3BJQkSCQAAbObkxZa0NgAAgGlUJAAAsBl3bQAAANMcnEfQ2gAAAOZRkQAAwG4OLkmQSAAAYDPu2gAAAPCBigQAADbjrg0AAGCag/MIEgkAAGzn4EyCNRIAAMA0KhIAANjMyXdtkEgAAGAzJy+2pLUBAABMoyIBAIDNHFyQoCIBAIDtXBZt1yA1NVUul0vDhg27thP9BokEAAAOl56erjlz5qhRo0aWn5tEAgAAm7ks+s+M8+fP68EHH9TcuXNVvnx5i6+MRAIAANu5XNZsZjz22GNKSkpSx44drb2o/4/FlgAAXCc8Ho88Ho/XmNvtltvt9nn88uXL9fHHHys9Pd22mKhIAABgM6vWWqampio8PNxrS01N9Tnn119/raFDh2rp0qUqXbq0fddmGIZh29n95OJlf0cAlEzlWzzu7xCAEufC7um2z3Hk9EVLzlO5rKvQFYm1a9fqf/7nfxQYGJg3lpOTI5fLpYCAAHk8Hq99ZtHaAADAZlY9IvtqbYzf6tChg/bu3es19sgjj+imm27SqFGjLEkiJBIJAAAcqVy5cmrQoIHXWJkyZVShQoV849eCRAIAAJs5+V0bJBIAANispOQRW7Zssfyc3LUBAABMoyIBAIDNaG0AAIBr4NxMgtYGAAAwjYoEAAA2o7UBAABMc3AeQWsDAACYR0UCAACb0doAAACmWfWujZKIRAIAALs5N49gjQQAADCPigQAADZzcEGCRAIAALs5ebElrQ0AAGAaFQkAAGzGXRsAAMA85+YRtDYAAIB5VCQAALCZgwsSJBIAANiNuzYAAAB8oCIBAIDNuGsDAACYRmsDAADABxIJAABgGq0NAABs5uTWBokEAAA2c/JiS1obAADANCoSAADYjNYGAAAwzcF5BK0NAABgHhUJAADs5uCSBIkEAAA2464NAAAAH6hIAABgM+7aAAAApjk4j6C1AQCA7VwWbUUwa9YsNWrUSGFhYQoLC1NCQoLefvttSy7n10gkAABwoD/96U+aMGGCMjIylJGRofbt2+uee+7RZ599Zuk8LsMwDEvPWAJcvOzvCICSqXyLx/0dAlDiXNg93f45sq05T0jQtX0/IiJC//jHP9SvXz9rAhJrJAAAsJ2/F1vm5OTo//7v/5SVlaWEhARLz00iAQDAdcLj8cjj8XiNud1uud1un8fv3btXCQkJunjxosqWLas1a9aoXr16lsbkyNYGSgaPx6PU1FSNHj26wP+RA39E/N2AWSkpKXr22We9xpKTk5WSkuLz+EuXLunYsWP66aeftGrVKs2bN09bt261NJkgkYBtzp49q/DwcJ05c0ZhYWH+DgcoMfi7AbOKWpH4rY4dOyouLk6vvPKKZTHR2gAA4DpRlKTBF8Mw8iUi14pEAgAAB3r66aeVmJioqlWr6ty5c1q+fLm2bNmiDRs2WDoPiQQAAA703Xff6eGHH9aJEycUHh6uRo0aacOGDerUqZOl85BIwDZut1vJycksJgN+g78bKA7z588vlnlYbAkAAEzjEdkAAMA0EgkAAGAaiQQAADCNRAIAAJhGIgHbzJw5U9WrV1fp0qXVrFkzffDBB/4OCfCrbdu2qWvXroqJiZHL5dLatWv9HRJwzUgkYIsVK1Zo2LBheuaZZ7R79261bt1aiYmJOnbsmL9DA/wmKytLjRs31vTp9r+2Gigu3P4JW7Rs2VJNmzbVrFmz8sbq1q2rbt26KTU11Y+RASWDy+XSmjVr1K1bN3+HAlwTKhKw3KVLl7Rr1y517tzZa7xz587asWOHn6ICANiBRAKWO3XqlHJychQVFeU1HhUVpczMTD9FBQCwA4kEbONyubw+G4aRbwwAcH0jkYDlKlasqMDAwHzVh5MnT+arUgAArm8kErBccHCwmjVrpo0bN3qNb9y4Ua1atfJTVAAAO/D2T9hi+PDhevjhh9W8eXMlJCRozpw5OnbsmAYNGuTv0AC/OX/+vA4cOJD3+fDhw9qzZ48iIiIUGxvrx8gA87j9E7aZOXOmJk2apBMnTqhBgwaaPHmybr/9dn+HBfjNli1b1K5du3zjvXv31qJFi4o/IMACJBIAAMA01kgAAADTSCQAAIBpJBIAAMA0EgkAAGAaiQQAADCNRAIAAJhGIgEAAEwjkQAcKCUlRU2aNMn73KdPH3Xr1q3Y4zhy5IhcLpf27NlT7HMDKB4kEkAx6tOnj1wul1wul4KCglSjRg099dRTysrKsnXel19+udBPTuSXP4Ci4F0bQDG78847tXDhQmVnZ+uDDz5Q//79lZWVpVmzZnkdl52draCgIEvmDA8Pt+Q8APBbVCSAYuZ2uxUdHa2qVauqV69eevDBB7V27dq8dsSCBQtUo0YNud1uGYahM2fO6NFHH1VkZKTCwsLUvn17ffLJJ17nnDBhgqKiolSuXDn169dPFy9e9Nr/29ZGbm6uJk6cqJo1a8rtdis2NlYvvPCCJKl69eqSpPj4eLlcLrVt2zbvewsXLlTdunVVunRp3XTTTZo5c6bXPB999JHi4+NVunRpNW/eXLt377bwJwegJKIiAfhZSEiIsrOzJUkHDhzQypUrtWrVKgUGBkqSkpKSFBERobfeekvh4eF65ZVX1KFDB+3fv18RERFauXKlkpOTNWPGDLVu3VpLlizR1KlTVaNGjQLnHD16tObOnavJkyfrtttu04kTJ/Sf//xH0i/JwM0336z33ntP9evXV3BwsCRp7ty5Sk5O1vTp0xUfH6/du3drwIABKlOmjHr37q2srCzdddddat++vZYuXarDhw9r6NChNv/0APidAaDY9O7d27jnnnvyPn/44YdGhQoVjO7duxvJyclGUFCQcfLkybz9mzZtMsLCwoyLFy96nScuLs545ZVXDMMwjISEBGPQoEFe+1u2bGk0btzY57xnz5413G63MXfuXJ8xHj582JBk7N6922u8atWqxuuvv+41Nm7cOCMhIcEwDMN45ZVXjIiICCMrKytv/6xZs3yeC4Bz0NoAitmbb76psmXLqnTp0kpISNDtt9+uadOmSZJuvPFGVapUKe/YXbt26fz586pQoYLKli2btx0+fFgHDx6UJH3xxRdKSEjwmuO3n3/tiy++kMfjUYcOHQod8/fff6+vv/5a/fr184rj+eef94qjcePGCg0NLVQcAJyB1gZQzNq1a6dZs2YpKChIMTExXgsqy5Qp43Vsbm6uKleurC1btuQ7zw033GBq/pCQkCJ/Jzc3V9Iv7Y2WLVt67bvSgjEMw1Q8AK5vJBJAMStTpoxq1qxZqGObNm2qzMxMlSpVStWqVfN5TN26dbVz50795S9/yRvbuXNngeesVauWQkJCtGnTJvXv3z/f/itrInJycvLGoqKiVKVKFR06dEgPPvigz/PWq1dPS5Ys0YULF/KSlavFAcAZaG0AJVjHjh2VkJCgbt266Z133tGRI0e0Y8cO/f3vf1dGRoYkaejQoVqwYIEWLFig/fv3Kzk5WZ999lmB5yxdurRGjRqlv/3tb3r11Vd18OBB7dy5U/Pnz5ckRUZGKiQkRBs2bNB3332nM2fOSPrlIVepqal6+eWXtX//fu3du1cLFy7USy+9JEnq1auXAgIC1K9fP33++ed666239OKLL9r8EwLgbyQSQAnmcrn01ltv6fbbb1ffvn1Vu3Zt9ezZU0eOHFFUVJQkqUePHho7dqxGjRqlZs2a6ejRoxo8ePBVzztmzBiNGDFCY8eOVd26ddWjRw+dPHlSklSqVClNnTpVr7zyimJiYnTPPfdIkvr376958+Zp0aJFatiwodq0aaNFixbl3S5atmxZrV+/Xp9//rni4+P1zDPPaOLEiTb+dACUBC6DxiYAADCJigQAADCNRAIAAJhGIgEAAEwjkQAAAKaRSAAAANNIJAAAgGkkEgAAwDQSCQAAYBqJBAAAMI1EAgAAmEYiAQAATCORAAAApv0/IinlH+mOmMMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['stacking_classifier.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "base_models = [\n",
    "    ('lr', Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=1000, random_state=42))])),\n",
    "    ('rf', Pipeline([('clf', RandomForestClassifier(random_state=42))])),\n",
    "    ('svm', Pipeline([('scaler', StandardScaler()), ('clf', SVC(random_state=42))])),\n",
    "    ('gb', Pipeline([('clf', GradientBoostingClassifier(random_state=42))])),\n",
    "    ('xgb', Pipeline([('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))])),\n",
    "    ('mlp', Pipeline([('scaler', StandardScaler()), ('clf', MLPClassifier(random_state=42, max_iter=500))]))\n",
    "]\n",
    "\n",
    "# Define the meta-model with polynomial features\n",
    "meta_model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Stacking Classifier\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Train and evaluate the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Stacking Classifier Model\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Cross-Validation for Stacking Classifier\n",
    "cv_scores = cross_val_score(stacking_clf, X_res, y_res, cv=StratifiedKFold(5))\n",
    "print(f\"Cross-Validation Accuracy for Stacking Classifier: {cv_scores.mean()} ± {cv_scores.std()}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Save the stacking classifier\n",
    "joblib.dump(stacking_clf, 'stacking_classifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
